#!/usr/bin/env node
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else {
		var a = factory();
		for(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];
	}
})(global, function() {
return /******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/plugins/github/bin/fetchAndPrintGithubOrg.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./src/graphql/mirror.js":
/*!*******************************!*\
  !*** ./src/graphql/mirror.js ***!
  \*******************************/
/*! exports provided: Mirror, _buildSchemaInfo, _FIELD_PREFIXES, _makeSingleUpdateFunction */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Mirror\", function() { return Mirror; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_buildSchemaInfo\", function() { return _buildSchemaInfo; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_FIELD_PREFIXES\", function() { return _FIELD_PREFIXES; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_makeSingleUpdateFunction\", function() { return _makeSingleUpdateFunction; });\n/* harmony import */ var deep_freeze__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! deep-freeze */ \"deep-freeze\");\n/* harmony import */ var deep_freeze__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(deep_freeze__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var json_stable_stringify__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! json-stable-stringify */ \"json-stable-stringify\");\n/* harmony import */ var json_stable_stringify__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(json_stable_stringify__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _util_dedent__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/dedent */ \"./src/util/dedent.js\");\n/* harmony import */ var _util_map__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/map */ \"./src/util/map.js\");\n/* harmony import */ var _util_null__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/null */ \"./src/util/null.js\");\n/* harmony import */ var _schema__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./schema */ \"./src/graphql/schema.js\");\n/* harmony import */ var _queries__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./queries */ \"./src/graphql/queries.js\");\nvar _templateObject,_templateObject2,_templateObject3,_templateObject4,_templateObject5,_templateObject6,_templateObject7,_templateObject8,_templateObject9,_templateObject10,_templateObject11,_templateObject12,_templateObject13,_templateObject14,_templateObject15,_templateObject16,_templateObject17,_templateObject18,_templateObject19,_templateObject20,_templateObject21,_templateObject22,_templateObject23,_templateObject24,_templateObject25,_templateObject26,_templateObject27,_templateObject28,_templateObject29,_templateObject30,_templateObject31,_templateObject32,_templateObject33,_templateObject34,_templateObject35,_templateObject36,_templateObject37;function _taggedTemplateLiteral(strings,raw){if(!raw){raw=strings.slice(0);}return Object.freeze(Object.defineProperties(strings,{raw:{value:Object.freeze(raw)}}));}function ownKeys(object,enumerableOnly){var keys=Object.keys(object);if(Object.getOwnPropertySymbols){var symbols=Object.getOwnPropertySymbols(object);if(enumerableOnly){symbols=symbols.filter(function(sym){return Object.getOwnPropertyDescriptor(object,sym).enumerable;});}keys.push.apply(keys,symbols);}return keys;}function _objectSpread(target){for(var i=1;i<arguments.length;i++){var source=arguments[i]!=null?arguments[i]:{};if(i%2){ownKeys(Object(source),true).forEach(function(key){_defineProperty(target,key,source[key]);});}else if(Object.getOwnPropertyDescriptors){Object.defineProperties(target,Object.getOwnPropertyDescriptors(source));}else{ownKeys(Object(source)).forEach(function(key){Object.defineProperty(target,key,Object.getOwnPropertyDescriptor(source,key));});}}return target;}function _defineProperty(obj,key,value){if(key in obj){Object.defineProperty(obj,key,{value:value,enumerable:true,configurable:true,writable:true});}else{obj[key]=value;}return obj;}/**\n * A local mirror of a subset of a GraphQL database.\n *\n * Clients should interact with this module as follows:\n *\n *   - Invoke the constructor to acquire a `Mirror` instance.\n *   - Invoke `registerObject` to register a root object of interest.\n *   - Invoke `update` to update all transitive dependencies.\n *   - Invoke `extract` to retrieve the data in structured form.\n *\n * See the relevant methods for documentation.\n */ /*\n * NOTE(perf): The implementation of this class is not particularly\n * optimized. In particular, when we interact with SQLite, we compile\n * our prepared statements many times over the lifespan of an\n * instance. It may be beneficial to precompile them at instance\n * construction time.\n */class Mirror{/**\n   * Create a GraphQL mirror using the given database connection and\n   * GraphQL schema.\n   *\n   * The connection must be to a database that either (a) is empty and\n   * unused, or (b) has been previously used for a GraphQL mirror with\n   * an identical GraphQL schema and options. The database attached to\n   * the connection must not be modified by any other clients. In other\n   * words, passing a connection to this constructor entails\n   * transferring ownership of the attached database to this module.\n   *\n   * If the database attached to the connection has been used with an\n   * incompatible GraphQL schema or an outdated version of this module,\n   * an error will be thrown and the database will remain unmodified.\n   *\n   * If a list of blacklisted IDs is provided, then any object with\n   * matching ID will be treated as `null` when it appears as the target\n   * of a node reference, nested node reference, or connection entry.\n   * This can be used to work around bugs in remote schemas.\n   *\n   * If `guessTypename` is provided, it should attempt to guess the\n   * typename of an object given its ID, returning `null` if no guess\n   * can be made. This will be used as a cross-check against results\n   * returned from the server to provide an early warning in cases where\n   * the results differ, potentially due to server-side contract\n   * violations. This option only affects console warnings, not the\n   * final state of the mirror.\n   */constructor(db,schema,options){_defineProperty(this,\"_db\",void 0);_defineProperty(this,\"_schema\",void 0);_defineProperty(this,\"_schemaInfo\",void 0);_defineProperty(this,\"_blacklistedIds\",void 0);_defineProperty(this,\"_guessTypename\",void 0);if(db==null)throw new Error(\"db: \"+String(db));if(schema==null)throw new Error(\"schema: \"+String(schema));const fullOptions=_objectSpread({blacklistedIds:[],guessTypename:()=>null},options||{});this._db=db;this._schema=schema;this._schemaInfo=_buildSchemaInfo(this._schema);this._blacklistedIds=(()=>{const result={};for(const id of fullOptions.blacklistedIds){result[id]=true;}return result;})();this._guessTypename=fullOptions.guessTypename;this._initialize();}/**\n   * Embed the GraphQL schema into the database, initializing it for use\n   * as a mirror.\n   *\n   * This method should only be invoked once, at construction time.\n   *\n   * If the database has already been initialized with the same schema\n   * and version, no action is taken and no error is thrown. If the\n   * database has been initialized with a different schema or version,\n   * the database is left unchanged, and an error is thrown.\n   *\n   * A discussion of the database structure follows.\n   *\n   * ---\n   *\n   * Objects have three kinds of fields: connections, links, and\n   * primitives. The database likewise has a `connections` table,\n   * `links` table, and `primitives` table, each storing corresponding\n   * data for all GraphQL object types.\n   *\n   * In more detail:\n   *\n   *   - The `connections` table has a row for each `(id, fieldname)`\n   *     pair, where `fieldname` is the name of a connection field on the\n   *     object with the given ID. This stores metadata about the\n   *     connection: its total count, when it was last updated, etc. It\n   *     does not store the actual entries in the connection (the nodes\n   *     that the connection points to); `connection_entries` stores\n   *     these.\n   *\n   *   - The `links` table has a row for each `(id, fieldname)` pair,\n   *     where `fieldname` is the name of a link field on the object\n   *     with the given ID. This simply points to the referenced object.\n   *\n   *   - The `primitives` table has a row for each `(id, fieldname)`\n   *     pair, where `fieldname` is the name of a (non-ID) primitive\n   *     field on the object with the given ID. The `value` column holds\n   *     the JSON-stringified primitive value: so, for instance, the\n   *     JSON value `null` is represented as the SQL string 'null',\n   *     _not_ SQL NULL, while the JSON string \"null\" is represented as\n   *     the SQL string '\"null\"'. This is primarily to accommodate\n   *     storing booleans: SQLite has no boolean storage class, and we\n   *     cannot simply encode `true` and `false` as `1` and `0` because\n   *     we need to be able to distinguish between these respective\n   *     values when we read them back out. There are other ways to do\n   *     this more efficiently in both space and time (see discussion on\n   *     #883 for some options).\n   *\n   * These fields are type-specific, and so only exist once a node's\n   * typename is set.\n   *\n   * We refer to node and primitive data together as \"own data\", because\n   * this is the data that can be queried uniformly for all elements of\n   * a type; querying connection data, by contrast, requires the\n   * object-specific end cursor.\n   *\n   * Nested fields merit additional explanation. The nested field itself\n   * exists on the `primitives` table with SQL value NULL, 0, or 1 (as\n   * SQL integers, not strings). As with all other primitives, `NULL`\n   * indicates that the value has never been fetched. If the value has\n   * been fetched, it is 0 if the nested field itself was `null` on the\n   * GraphQL result, or 1 if it was present. This field lets us\n   * distinguish \"author: null\" from \"author: {user: null}\".\n   *\n   * The \"eggs\" of a nested field are treated as normal primitive or\n   * link values, whose fieldname is the nested fieldname and egg\n   * fieldname joined by a period. So, if object type `Foo` has nested\n   * field `bar: Schema.nested({baz: Schema.primitive()})`, then the\n   * `primitives` table will include a row with fieldname 'bar.baz'.\n   * Likewise, a row in the `links` table might have fieldname\n   * 'quux.zod'.\n   *\n   * All aforementioned tables are keyed by object ID. Each object also\n   * appears once in the `objects` table, which relates its ID,\n   * typename, and last own-data update. Each connection has its own\n   * last-update value, because connections can be updated independently\n   * of each other and of own-data. An object's typename may be `NULL`\n   * if we have only reached the object through edges of unfaithful\n   * type, in which case we will perform an extra query to definitively\n   * determine fetch the object's type before requesting its own data or\n   * connections.\n   *\n   * Note that any object in the database should have entries in the\n   * `connections`, `links`, and `primitives` tables for all relevant\n   * fields, even if the node has never been updated. This is for\n   * convenience of implementation: it means that the first fetch for a\n   * node is the same as subsequent fetches (a simple SQL `UPDATE`\n   * instead of first requiring an existence check).\n   *\n   * A table `network_log` logs all GraphQL requests made by this module\n   * and their corresponding responses, as well as the update created\n   * from the response. This is for debugging. For example, if a node in\n   * the database is corrupt in some way, inspecting the network log\n   * will show exactly which queries caused it to enter its broken\n   * state. In theory, it should be possible to replay the network log\n   * to re-create the database state exactly, though no tooling exists\n   * to do so automatically.\n   *\n   * Finally, a table `meta` is used to store metadata about the mirror\n   * itself. This is used to make sure that the mirror is not loaded\n   * with an incompatible version of the code or schema. It is never\n   * updated after it is first set.\n   */_initialize(){// The following version number must be updated if there is any\n// change to the way in which a GraphQL schema is mapped to a SQL\n// schema or the way in which the resulting SQL schema is\n// interpreted. If you've made a change and you're not sure whether\n// it requires bumping the version, bump it: requiring some extra\n// one-time cache resets is okay; doing the wrong thing is not.\nconst blob=json_stable_stringify__WEBPACK_IMPORTED_MODULE_1___default()({version:\"MIRROR_v9\",schema:this._schema,options:{blacklistedIds:this._blacklistedIds}});const db=this._db;db.transaction(()=>{// We store the metadata in a singleton table `meta`, whose unique row\n// has primary key `0`. Only the first ever insert will succeed; we\n// are locked into the first config.\ndb.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject||(_templateObject=_taggedTemplateLiteral([\"          CREATE TABLE IF NOT EXISTS meta (\\n              zero INTEGER PRIMARY KEY,\\n              config TEXT NOT NULL\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE IF NOT EXISTS meta (\\n              zero INTEGER PRIMARY KEY,\\n              config TEXT NOT NULL\\n          )\\n        \"])))).run();const existingBlob=db.prepare(\"SELECT config FROM meta\").pluck().get();if(existingBlob===blob){// Already set up; nothing to do.\nreturn;}else if(existingBlob!==undefined){throw new Error(\"Database already populated with \"+\"incompatible schema, options, or version\");}db.prepare(\"INSERT INTO meta (zero, config) VALUES (0, ?)\").run(blob);const tables=[// Time is stored in milliseconds since 1970-01-01T00:00Z, with\n// ECMAScript semantics (leap seconds ignored, exactly 86.4M ms\n// per day, etc.).\n//\n// We use milliseconds rather than seconds because (a) this\n// simplifies JavaScript interop to a simple `+new Date()` and\n// `new Date(value)`, and (b) this avoids a lurking Year 2038\n// problem by surfacing >32-bit values immediately. (We have\n// over 200,000 years before the number of milliseconds since\n// epoch is more than `Number.MAX_SAFE_INTEGER`.)\nObject(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject2||(_templateObject2=_taggedTemplateLiteral([\"          CREATE TABLE updates (\\n              rowid INTEGER PRIMARY KEY,\\n              time_epoch_millis INTEGER NOT NULL\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE updates (\\n              rowid INTEGER PRIMARY KEY,\\n              time_epoch_millis INTEGER NOT NULL\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject3||(_templateObject3=_taggedTemplateLiteral([\"          CREATE TABLE objects (\\n              id TEXT NOT NULL PRIMARY KEY,\\n              typename TEXT,\\n              last_update INTEGER,\\n              FOREIGN KEY(last_update) REFERENCES updates(rowid),\\n              CHECK((last_update IS NOT NULL) <= (typename IS NOT NULL))\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE objects (\\n              id TEXT NOT NULL PRIMARY KEY,\\n              typename TEXT,\\n              last_update INTEGER,\\n              FOREIGN KEY(last_update) REFERENCES updates(rowid),\\n              CHECK((last_update IS NOT NULL) <= (typename IS NOT NULL))\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject4||(_templateObject4=_taggedTemplateLiteral([\"          CREATE TABLE primitives (\\n              rowid INTEGER PRIMARY KEY,\\n              object_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              value,  -- JSON string, or SQL 0 or 1 for nest fields\\n              UNIQUE(object_id, fieldname),\\n              FOREIGN KEY(object_id) REFERENCES objects(id)\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE primitives (\\n              rowid INTEGER PRIMARY KEY,\\n              object_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              value,  -- JSON string, or SQL 0 or 1 for nest fields\\n              UNIQUE(object_id, fieldname),\\n              FOREIGN KEY(object_id) REFERENCES objects(id)\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject5||(_templateObject5=_taggedTemplateLiteral([\"          CREATE UNIQUE INDEX idx_primitives__object_id__fieldname\\n          ON primitives (object_id, fieldname)\\n        \"],[\"\\\\\\n          CREATE UNIQUE INDEX idx_primitives__object_id__fieldname\\n          ON primitives (object_id, fieldname)\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject6||(_templateObject6=_taggedTemplateLiteral([\"          CREATE TABLE links (\\n              rowid INTEGER PRIMARY KEY,\\n              parent_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              child_id TEXT,\\n              UNIQUE(parent_id, fieldname),\\n              FOREIGN KEY(parent_id) REFERENCES objects(id),\\n              FOREIGN KEY(child_id) REFERENCES objects(id)\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE links (\\n              rowid INTEGER PRIMARY KEY,\\n              parent_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              child_id TEXT,\\n              UNIQUE(parent_id, fieldname),\\n              FOREIGN KEY(parent_id) REFERENCES objects(id),\\n              FOREIGN KEY(child_id) REFERENCES objects(id)\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject7||(_templateObject7=_taggedTemplateLiteral([\"          CREATE UNIQUE INDEX idx_links__parent_id__fieldname\\n          ON links (parent_id, fieldname)\\n        \"],[\"\\\\\\n          CREATE UNIQUE INDEX idx_links__parent_id__fieldname\\n          ON links (parent_id, fieldname)\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject8||(_templateObject8=_taggedTemplateLiteral([\"          CREATE TABLE connections (\\n              rowid INTEGER PRIMARY KEY,\\n              object_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              last_update INTEGER,\\n              -- Each of the below fields must be NULL if the connection\\n              -- has never been updated.\\n              total_count INTEGER,\\n              has_next_page BOOLEAN,\\n              -- The end cursor may be NULL if no items are in the connection;\\n              -- this is a consequence of GraphQL and the Relay pagination spec.\\n              -- (It may also be NULL if the connection was never updated.)\\n              end_cursor TEXT,\\n              CHECK((last_update IS NULL) = (total_count IS NULL)),\\n              CHECK((last_update IS NULL) = (has_next_page IS NULL)),\\n              CHECK((last_update IS NULL) <= (end_cursor IS NULL)),\\n              UNIQUE(object_id, fieldname),\\n              FOREIGN KEY(object_id) REFERENCES objects(id),\\n              FOREIGN KEY(last_update) REFERENCES updates(rowid)\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE connections (\\n              rowid INTEGER PRIMARY KEY,\\n              object_id TEXT NOT NULL,\\n              fieldname TEXT NOT NULL,\\n              last_update INTEGER,\\n              -- Each of the below fields must be NULL if the connection\\n              -- has never been updated.\\n              total_count INTEGER,\\n              has_next_page BOOLEAN,\\n              -- The end cursor may be NULL if no items are in the connection;\\n              -- this is a consequence of GraphQL and the Relay pagination spec.\\n              -- (It may also be NULL if the connection was never updated.)\\n              end_cursor TEXT,\\n              CHECK((last_update IS NULL) = (total_count IS NULL)),\\n              CHECK((last_update IS NULL) = (has_next_page IS NULL)),\\n              CHECK((last_update IS NULL) <= (end_cursor IS NULL)),\\n              UNIQUE(object_id, fieldname),\\n              FOREIGN KEY(object_id) REFERENCES objects(id),\\n              FOREIGN KEY(last_update) REFERENCES updates(rowid)\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject9||(_templateObject9=_taggedTemplateLiteral([\"          CREATE UNIQUE INDEX idx_connections__object_id__fieldname\\n          ON connections (object_id, fieldname)\\n        \"],[\"\\\\\\n          CREATE UNIQUE INDEX idx_connections__object_id__fieldname\\n          ON connections (object_id, fieldname)\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject10||(_templateObject10=_taggedTemplateLiteral([\"          CREATE TABLE connection_entries (\\n              rowid INTEGER PRIMARY KEY,\\n              connection_id INTEGER NOT NULL,\\n              idx INTEGER NOT NULL,  -- impose an ordering\\n              child_id TEXT,\\n              UNIQUE(connection_id, idx),\\n              FOREIGN KEY(connection_id) REFERENCES connections(rowid),\\n              FOREIGN KEY(child_id) REFERENCES objects(id)\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE connection_entries (\\n              rowid INTEGER PRIMARY KEY,\\n              connection_id INTEGER NOT NULL,\\n              idx INTEGER NOT NULL,  -- impose an ordering\\n              child_id TEXT,\\n              UNIQUE(connection_id, idx),\\n              FOREIGN KEY(connection_id) REFERENCES connections(rowid),\\n              FOREIGN KEY(child_id) REFERENCES objects(id)\\n          )\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject11||(_templateObject11=_taggedTemplateLiteral([\"          CREATE INDEX idx_connection_entries__connection_id\\n          ON connection_entries (connection_id)\\n        \"],[\"\\\\\\n          CREATE INDEX idx_connection_entries__connection_id\\n          ON connection_entries (connection_id)\\n        \"]))),Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject12||(_templateObject12=_taggedTemplateLiteral([\"          CREATE TABLE network_log (\\n              rowid INTEGER PRIMARY KEY,\\n              query TEXT,\\n              query_parameters TEXT,  -- stringified JSON object\\n              request_time_epoch_millis INTEGER,\\n              response TEXT,\\n              response_time_epoch_millis INTEGER,\\n              update_id INTEGER,\\n              CHECK((query IS NULL) = (query_parameters IS NULL)),\\n              CHECK((request_time_epoch_millis IS NULL) = (query IS NULL)),\\n              CHECK((response_time_epoch_millis IS NULL) = (response IS NULL)),\\n              FOREIGN KEY(update_id) REFERENCES updates(rowid)\\n          )\\n        \"],[\"\\\\\\n          CREATE TABLE network_log (\\n              rowid INTEGER PRIMARY KEY,\\n              query TEXT,\\n              query_parameters TEXT,  -- stringified JSON object\\n              request_time_epoch_millis INTEGER,\\n              response TEXT,\\n              response_time_epoch_millis INTEGER,\\n              update_id INTEGER,\\n              CHECK((query IS NULL) = (query_parameters IS NULL)),\\n              CHECK((request_time_epoch_millis IS NULL) = (query IS NULL)),\\n              CHECK((response_time_epoch_millis IS NULL) = (response IS NULL)),\\n              FOREIGN KEY(update_id) REFERENCES updates(rowid)\\n          )\\n        \"])))];for(const sql of tables){db.prepare(sql).run();}})();}/**\n   * Register a new update, representing one communication with the\n   * remote server. A unique ID will be created and returned.\n   */_createUpdate(updateTimestamp){return this._db.prepare(\"INSERT INTO updates (time_epoch_millis) VALUES (?)\").run(+updateTimestamp).lastInsertRowid;}/**\n   * Inform the GraphQL mirror of the existence of an object. The\n   * object's ID must be specified. The object's concrete type may also\n   * be specified, in which case it must be an OBJECT type in the\n   * GraphQL schema.\n   *\n   * If the object has previously been registered with the same type, no\n   * action is taken and no error is raised. If the object has\n   * previously been registered with a different type, an error is\n   * thrown, and the database is left unchanged.\n   */registerObject(object){this._db.transaction(()=>{this._nontransactionallyRegisterObject(object);})();}/**\n   * As `registerObject`, but do not enter any transactions. Other\n   * methods may call this method as a subroutine in a larger\n   * transaction.\n   *\n   * This internal method also permits registering an object without\n   * specifying its typename.\n   */_nontransactionallyRegisterObject(object,guessMismatchMessage){const db=this._db;const{typename,id}=object;if(guessMismatchMessage==null){guessMismatchMessage=guess=>{const s=JSON.stringify;const message=\"object \".concat(s(object.id),\" \")+\"looks like it should have type \".concat(s(guess),\", \")+\"not \".concat(s(object.typename));return message;};}const existingTypename=db.prepare(\"SELECT typename FROM objects WHERE id = ?\").pluck().get(id);if(existingTypename===typename){// Already registered, and no typename upgrade; nothing to do.\nreturn;}else if(existingTypename!=null&&typename==null){// Already registered, and already have typename; nothing to do.\nreturn;}else if(existingTypename===undefined){// OK: New registration.\n}else if(existingTypename===null){// OK: Typename upgrade. Take the user-supplied type as reliable.\n// We still need to add primitives, links, and connections rows.\n}else{// Not OK: Already had a typename, but it didn't match.\nconst s=JSON.stringify;throw new Error(\"Inconsistent type for ID \".concat(s(id),\": \")+\"expected \".concat(s(existingTypename),\", got \").concat(s(typename)));}if(typename!=null){if(this._schema[typename]==null){throw new Error(\"Unknown type: \"+JSON.stringify(typename));}if(this._schema[typename].type!==\"OBJECT\"){throw new Error(\"Cannot add object of non-object type: \"+\"\".concat(JSON.stringify(typename),\" (\").concat(this._schema[typename].type,\")\"));}const guess=this._guessTypename(object.id);if(guess!=null&&guess!==object.typename){console.warn(\"Warning: \"+guessMismatchMessage(guess));}}if(existingTypename===undefined){this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject13||(_templateObject13=_taggedTemplateLiteral([\"            INSERT INTO objects (id, last_update, typename)\\n            VALUES (:id, NULL, :typename)\\n          \"],[\"\\\\\\n            INSERT INTO objects (id, last_update, typename)\\n            VALUES (:id, NULL, :typename)\\n          \"])))).run({id,typename});}else{// Should be a typename upgrade.\nconst stmt=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject14||(_templateObject14=_taggedTemplateLiteral([\"          UPDATE objects SET typename = :typename\\n          WHERE id = :id\\n          AND typename IS NULL  -- sanity check\\n          AND :typename IS NOT NULL  -- sanity check\\n        \"],[\"\\\\\\n          UPDATE objects SET typename = :typename\\n          WHERE id = :id\\n          AND typename IS NULL  -- sanity check\\n          AND :typename IS NOT NULL  -- sanity check\\n        \"]))));_makeSingleUpdateFunction(stmt)({id,typename});}if(typename==null){// Can't add fields if typename not known.\nreturn;}const addPrimitive=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject15||(_templateObject15=_taggedTemplateLiteral([\"\\n        INSERT INTO primitives (object_id, fieldname, value)\\n        VALUES (:id, :fieldname, NULL)\\n      \"]))));const addLink=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject16||(_templateObject16=_taggedTemplateLiteral([\"        INSERT INTO links (parent_id, fieldname, child_id)\\n        VALUES (:id, :fieldname, NULL)\\n      \"],[\"\\\\\\n        INSERT INTO links (parent_id, fieldname, child_id)\\n        VALUES (:id, :fieldname, NULL)\\n      \"]))));const addConnection=this._db.prepare(// These fields are initialized to NULL because there has\n// been no update and so they have no meaningful values:\n// last_update, total_count, has_next_page, end_cursor.\nObject(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject17||(_templateObject17=_taggedTemplateLiteral([\"        INSERT INTO connections (object_id, fieldname)\\n        VALUES (:id, :fieldname)\\n      \"],[\"\\\\\\n        INSERT INTO connections (object_id, fieldname)\\n        VALUES (:id, :fieldname)\\n      \"]))));const objectType=this._schemaInfo.objectTypes[typename];for(const fieldname of objectType.primitiveFieldNames){addPrimitive.run({id,fieldname});}for(const fieldname of objectType.linkFieldNames){addLink.run({id,fieldname});}for(const parentFieldname of objectType.nestedFieldNames){addPrimitive.run({id,fieldname:parentFieldname});const children=objectType.nestedFields[parentFieldname];for(const childFieldname of Object.keys(children.primitives)){const fieldname=\"\".concat(parentFieldname,\".\").concat(childFieldname);addPrimitive.run({id,fieldname});}for(const childFieldname of Object.keys(children.nodes)){const fieldname=\"\".concat(parentFieldname,\".\").concat(childFieldname);addLink.run({id,fieldname});}}for(const fieldname of objectType.connectionFieldNames){addConnection.run({id,fieldname});}}/**\n   * Register an object corresponding to the provided `NodeFieldResult`,\n   * if any, returning the object's ID. If the provided value is `null`,\n   * no action is taken, no error is thrown, and `null` is returned.\n   *\n   * As with `registerObject`, an error is thrown if an object by the\n   * given ID already exists with a different typename.\n   *\n   * This method does not begin or end any transactions. Other methods\n   * may call this method as a subroutine in a larger transaction.\n   *\n   * See: `registerObject`.\n   */_nontransactionallyRegisterNodeFieldResult(result,context){if(result==null){return null;}else if(this._blacklistedIds[result.id]){return null;}else{// If queried via an unfaithful field, typename will be missing;\n// in that case, register the object with unknown type (`null`).\nconst typename=result.__typename===undefined?null:result.__typename;const id=result.id;const object={typename,id};this._nontransactionallyRegisterObject(object,guess=>{const s=JSON.stringify;const message=\"object \".concat(s(object.id),\" \")+\"looks like it should have type \".concat(s(guess),\", \")+\"but the server claims that it has type \".concat(s(object.typename));return\"\".concat(context(),\": \").concat(message);});return object.id;}}/**\n   * Find objects and connections that are not known to be up-to-date.\n   *\n   * An object's typename is up-to-date if it has ever been fetched from\n   * a faithful field reference or a direct typename query.\n   *\n   * An object is up-to-date if its own data has been loaded at least as\n   * recently as the provided date.\n   *\n   * A connection is up-to-date if it has been fetched at least as\n   * recently as the provided date, and at the time of fetching there\n   * were no more pages.\n   */_findOutdated(since){const db=this._db;return db.transaction(()=>{const typenames=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject18||(_templateObject18=_taggedTemplateLiteral([\"            SELECT id AS id\\n            FROM objects\\n            WHERE typename IS NULL\\n          \"],[\"\\\\\\n            SELECT id AS id\\n            FROM objects\\n            WHERE typename IS NULL\\n          \"])))).pluck().all();const objects=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject19||(_templateObject19=_taggedTemplateLiteral([\"            SELECT typename AS typename, id AS id\\n            FROM objects\\n            LEFT OUTER JOIN updates ON objects.last_update = updates.rowid\\n            WHERE\\n                typename IS NOT NULL\\n                AND (\\n                    objects.last_update IS NULL\\n                    OR updates.time_epoch_millis < :timeEpochMillisThreshold\\n                )\\n          \"],[\"\\\\\\n            SELECT typename AS typename, id AS id\\n            FROM objects\\n            LEFT OUTER JOIN updates ON objects.last_update = updates.rowid\\n            WHERE\\n                typename IS NOT NULL\\n                AND (\\n                    objects.last_update IS NULL\\n                    OR updates.time_epoch_millis < :timeEpochMillisThreshold\\n                )\\n          \"])))).all({timeEpochMillisThreshold:+since});const connections=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject20||(_templateObject20=_taggedTemplateLiteral([\"            SELECT\\n                objects.typename AS objectTypename,\\n                connections.object_id AS objectId,\\n                connections.fieldname AS fieldname,\\n                connections.last_update IS NULL AS neverUpdated,\\n                connections.end_cursor AS endCursor\\n            FROM connections\\n            LEFT OUTER JOIN updates\\n                ON connections.last_update = updates.rowid\\n            JOIN objects\\n                ON connections.object_id = objects.id\\n            WHERE\\n                objectTypename IS NOT NULL\\n                AND (\\n                    connections.has_next_page\\n                    OR connections.last_update IS NULL\\n                    OR updates.time_epoch_millis < :timeEpochMillisThreshold\\n                )\\n          \"],[\"\\\\\\n            SELECT\\n                objects.typename AS objectTypename,\\n                connections.object_id AS objectId,\\n                connections.fieldname AS fieldname,\\n                connections.last_update IS NULL AS neverUpdated,\\n                connections.end_cursor AS endCursor\\n            FROM connections\\n            LEFT OUTER JOIN updates\\n                ON connections.last_update = updates.rowid\\n            JOIN objects\\n                ON connections.object_id = objects.id\\n            WHERE\\n                objectTypename IS NOT NULL\\n                AND (\\n                    connections.has_next_page\\n                    OR connections.last_update IS NULL\\n                    OR updates.time_epoch_millis < :timeEpochMillisThreshold\\n                )\\n          \"])))).all({timeEpochMillisThreshold:+since}).map(entry=>{const result=_objectSpread({},entry);if(result.neverUpdated){result.endCursor=undefined;// as opposed to `null`\n}delete result.neverUpdated;return result;});return{typenames,objects,connections};})();}/**\n   * Check whether the given query plan indicates that the mirror is\n   * already up to date and no further queries are required.\n   */_isUpToDate(queryPlan){return queryPlan.typenames.length===0&&queryPlan.objects.length===0&&queryPlan.connections.length===0;}/**\n   * Create a GraphQL selection set to fetch data corresponding to the\n   * given query plan.\n   *\n   * The resulting GraphQL should be embedded into a top-level query.\n   *\n   * The result of this query is an `UpdateResult`.\n   *\n   * This function is pure: it does not interact with the database.\n   */_queryFromPlan(queryPlan,options){const fetchTypenamesFor=queryPlan.typenames.slice(0,options.typenamesLimit);const typenameBatches=[];for(let i=0;i<fetchTypenamesFor.length;i+=options.nodesOfTypeLimit){typenameBatches.push(fetchTypenamesFor.slice(i,i+options.nodesOfTypeLimit));}// Group objects by type, so that we have to specify each type's\n// fieldset fewer times (only once per `nodesOfTypeLimit` nodes\n// instead of for every node).\nconst objectsByType=new Map();for(const object of queryPlan.objects.slice(0,options.nodesLimit)){_util_map__WEBPACK_IMPORTED_MODULE_3__[\"pushValue\"](objectsByType,object.typename,object.id);}const paginatedObjectsByType=[];for(const[typename,allIds]of objectsByType.entries()){for(let i=0;i<allIds.length;i+=options.nodesOfTypeLimit){const ids=allIds.slice(i,i+options.nodesOfTypeLimit);paginatedObjectsByType.push({typename,ids});}}// Group connections by object, so that we only have to fetch the\n// node once.\nconst connectionsByObject=new Map();for(const connection of queryPlan.connections.slice(0,options.connectionLimit)){let existing=connectionsByObject.get(connection.objectId);if(existing==null){existing={typename:connection.objectTypename,connections:[]};connectionsByObject.set(connection.objectId,existing);}else{if(connection.objectTypename!==existing.typename){const s=JSON.stringify;throw new Error(\"Query plan has inconsistent typenames for \"+\"object \".concat(s(connection.objectId),\": \")+\"\".concat(s(existing.typename),\" vs. \").concat(s(connection.objectTypename)));}}existing.connections.push({fieldname:connection.fieldname,endCursor:connection.endCursor});}const b=_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"];// Each top-level field other than `typenames` corresponds to either\n// an object type (fetching own data for objects of that type) or a\n// particular node (updating connections on that node). We alias\n// each such field, which is necessary to ensure that their names\n// are all unique. The names chosen are sufficient to identify which\n// _kind_ of query the field corresponds to (type's own data vs\n// node's connections), but do not need to identify the particular\n// type or node in question. This is because all descendant\n// selections are self-describing: they include the ID of any\n// relevant objects.\nreturn[].concat(typenameBatches.map((typenames,i)=>{const name=\"\".concat(_FIELD_PREFIXES.TYPENAMES).concat(i);return b.alias(name,b.field(\"nodes\",{ids:b.list(typenames.map(id=>b.literal(id)))},this._queryTypename()));}),paginatedObjectsByType.map((_ref,i)=>{let{typename,ids}=_ref;const name=\"\".concat(_FIELD_PREFIXES.OWN_DATA).concat(i);return b.alias(name,b.field(\"nodes\",{ids:b.list(ids.map(id=>b.literal(id)))},[b.inlineFragment(typename,this._queryOwnData(typename))]));}),_util_map__WEBPACK_IMPORTED_MODULE_3__[\"mapToArray\"](connectionsByObject,(_ref2,i)=>{let[id,{typename,connections}]=_ref2;const name=\"\".concat(_FIELD_PREFIXES.NODE_CONNECTIONS).concat(i);return b.alias(name,b.field(\"node\",{id:b.literal(id)},[b.field(\"id\"),b.inlineFragment(typename,[].concat(...connections.map(_ref3=>{let{fieldname,endCursor}=_ref3;return this._queryConnection(typename,fieldname,endCursor,options.connectionPageSize);})))]));}));}/**\n   * Ingest data given by an `UpdateResult`. This is porcelain over\n   * `_updateConnection` and `_updateOwnData`.\n   *\n   * See: `_findOutdated`.\n   * See: `_queryFromPlan`.\n   */_updateData(updateId,queryResult){this._db.transaction(()=>{this._nontransactionallyUpdateData(updateId,queryResult);})();}/**\n   * As `_updateData`, but do not enter any transactions. Other methods\n   * may call this method as a subroutine in a larger transaction.\n   */_nontransactionallyUpdateData(updateId,queryResult){for(const topLevelKey of Object.keys(queryResult)){const rawValue=queryResult[topLevelKey];if(topLevelKey.startsWith(_FIELD_PREFIXES.TYPENAMES)){const updateRecord=rawValue;this._nontransactionallyUpdateTypenames(updateRecord);}else if(topLevelKey.startsWith(_FIELD_PREFIXES.OWN_DATA)){const updateRecord=rawValue;this._nontransactionallyUpdateOwnData(updateId,updateRecord);}else if(topLevelKey.startsWith(_FIELD_PREFIXES.NODE_CONNECTIONS)){const updateRecord=rawValue;for(const fieldname of Object.keys(updateRecord)){if(fieldname===\"id\"){continue;}this._nontransactionallyUpdateConnection(updateId,updateRecord.id,fieldname,updateRecord[fieldname]);}}else{throw new Error(\"Bad key in query result: \"+JSON.stringify(topLevelKey));}}}/**\n   * Save the request query and query parameters to the database.\n   */_logRequest(body,variables,timestamp){const query=_queries__WEBPACK_IMPORTED_MODULE_6__[\"stringify\"].body(body,_queries__WEBPACK_IMPORTED_MODULE_6__[\"inlineLayout\"]());const queryParameters=json_stable_stringify__WEBPACK_IMPORTED_MODULE_1___default()(variables);return this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject21||(_templateObject21=_taggedTemplateLiteral([\"          INSERT INTO network_log (\\n              query, query_parameters, request_time_epoch_millis\\n          )\\n          VALUES (:query, :queryParameters, :requestTimestamp)\\n        \"],[\"\\\\\\n          INSERT INTO network_log (\\n              query, query_parameters, request_time_epoch_millis\\n          )\\n          VALUES (:query, :queryParameters, :requestTimestamp)\\n        \"])))).run({query,queryParameters,requestTimestamp:+timestamp}).lastInsertRowid;}/**\n   * Save the network response and response timestamp to the table row\n   * corresponding to the request that generated it.\n   */_logResponse(rowid,jsonResponse,timestamp){const response=json_stable_stringify__WEBPACK_IMPORTED_MODULE_1___default()(jsonResponse);const stmt=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject22||(_templateObject22=_taggedTemplateLiteral([\"        UPDATE network_log\\n        SET\\n            response = :response,\\n            response_time_epoch_millis = :responseTimestamp\\n        WHERE rowid = :rowid\\n      \"],[\"\\\\\\n        UPDATE network_log\\n        SET\\n            response = :response,\\n            response_time_epoch_millis = :responseTimestamp\\n        WHERE rowid = :rowid\\n      \"]))));const saveResponse=_makeSingleUpdateFunction(stmt);saveResponse({response,responseTimestamp:+timestamp,rowid});}/**\n   * Save the UpdateId in the table row corresponding to the network request\n   * that generated it.\n   */_logRequestUpdateId(rowid,updateId){const stmt=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject23||(_templateObject23=_taggedTemplateLiteral([\"        UPDATE network_log\\n        SET\\n            update_id = :updateId\\n        WHERE rowid = :rowid\\n      \"],[\"\\\\\\n        UPDATE network_log\\n        SET\\n            update_id = :updateId\\n        WHERE rowid = :rowid\\n      \"]))));const saveUpdateId=_makeSingleUpdateFunction(stmt);saveUpdateId({rowid,updateId});}/**\n   * Perform one step of the update loop: find outdated entities, fetch\n   * their updates, and feed the results back into the database.\n   *\n   * Returns a promise that resolves to `true` if any changes were made.\n   */async _updateStep(postQuery,options){const queryPlan=this._findOutdated(options.since);if(this._isUpToDate(queryPlan)){return Promise.resolve(false);}const querySelections=this._queryFromPlan(queryPlan,{// TODO(@wchargin): Expose `typenamesLimit` as an option and fix\n// up callers.\ntypenamesLimit:options.nodesLimit,nodesLimit:options.nodesLimit,nodesOfTypeLimit:options.nodesOfTypeLimit,connectionPageSize:options.connectionPageSize,connectionLimit:options.connectionLimit});const body=[_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"].query(\"MirrorUpdate\",[],querySelections)];const variables={};const requestRowId=this._logRequest(body,variables,options.now());const result=await postQuery({body,variables});this._logResponse(requestRowId,result,options.now());this._db.transaction(()=>{const updateId=this._createUpdate(options.now());this._logRequestUpdateId(requestRowId,updateId);this._nontransactionallyUpdateData(updateId,result);})();return Promise.resolve(true);}/**\n   * Update this mirror with new information from a remote GraphQL\n   * server.\n   *\n   * The `postQuery` function should post a GraphQL query to the remote\n   * server and return the `data` contents of its response, rejecting if\n   * there are any errors. (Note that this requirement may change\n   * backward-incompatibly in future versions of this module, in the\n   * case that we wish to handle deletions without regenerating all\n   * data.)\n   *\n   * The options are as follows:\n   *\n   *   - `since`: Fetch all data that is not known to be up-to-date as\n   *     of the provided time. For instance, to fetch all objects more\n   *     than a day old, use `new Date(new Date() - 86400e3)`.\n   *\n   *   - `now`: Function to yield the current date, which will be used\n   *     as the modification time for any objects or connections updated\n   *     in this process. Should probably be `() => new Date()`.\n   *\n   *   - `connectionPageSize`: Maximum number of entries to fetch in any\n   *     given connection. Some providers have a hard limit of 100 on\n   *     this value.\n   *\n   *   - `connectionLimit`: Maximum number of connections to fetch in a\n   *     single query.\n   *\n   * See: `registerObject`.\n   * See: `extract`.\n   */async update(postQuery,options){while(await this._updateStep(postQuery,options));}/**\n   * Create a GraphQL selection set required to identify an object of\n   * the given declared type, which may be either an object type or a\n   * union type. This is the minimal required data whenever we find a\n   * reference to an object that we want to traverse later.\n   *\n   * The `fidelity` argument should be the fidelity of the field being\n   * traversed. If it is faithful, the object's typename will be queried\n   * as well; if it is unfaithful, the typename will not be requested.\n   *\n   * The resulting GraphQL should be embedded in the context of any node\n   * of the provided type. For instance, `_queryShallow(\"Issue\")`\n   * returns a selection set that might replace the `?` in any of the\n   * following queries:\n   *\n   *     repository(owner: \"foo\", name: \"bar\") {\n   *       issues(first: 1) {\n   *         nodes { ? }\n   *       }\n   *     }\n   *\n   *     nodes(ids: [\"issue#1\", \"issue#2\"]) { ? }\n   *\n   * The result of this query has type `NodeFieldResult`.\n   *\n   * This function is pure: it does not interact with the database.\n   */_queryShallow(typename,fidelity){const type=this._schema[typename];if(type==null){// Should not be reachable via APIs.\nthrow new Error(\"No such type: \"+JSON.stringify(typename));}const b=_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"];const typenameQuery=[];switch(fidelity.type){case\"FAITHFUL\":typenameQuery.push(b.field(\"__typename\"));break;case\"UNFAITHFUL\":// Do not query typename.\nbreak;// istanbul ignore next\ndefault:throw new Error(fidelity.type);}switch(type.type){case\"SCALAR\":throw new Error(\"Cannot create selections for scalar type: \"+JSON.stringify(typename));case\"ENUM\":throw new Error(\"Cannot create selections for enum type: \"+JSON.stringify(typename));case\"OBJECT\":return[...typenameQuery,b.field(\"id\")];case\"UNION\":return[// Known issue: This selection set may be empty if the field\n// is unfaithful and the union type has no clauses. This would\n// emit an invalid GraphQL query; the GraphQL syntax requires\n// at least one selection. However, empty union types are also\n// disallowed in GraphQL, so this should not be a problem on a\n// well-formed schema. Handling this properly would require\n// transitively upward-pruning the query and seems unlikely to\n// be worth it at this time.\n...typenameQuery,...this._schemaInfo.unionTypes[typename].clauses.map(clause=>b.inlineFragment(clause,[b.field(\"id\")]))];// istanbul ignore next\ndefault:throw new Error(type.type);}}/**\n   * Get the current value of the end cursor on a connection, or\n   * `undefined` if the object has never been fetched. If no object by\n   * the given ID is known, or the object does not have a connection of\n   * the given name, then an error is thrown.\n   *\n   * Note that `null` is a valid end cursor and is distinct from\n   * `undefined`.\n   */_getEndCursor(objectId,fieldname){const result=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject24||(_templateObject24=_taggedTemplateLiteral([\"          SELECT\\n              last_update IS NOT NULL AS initialized,\\n              end_cursor AS endCursor\\n          FROM connections\\n          WHERE object_id = :objectId AND fieldname = :fieldname\\n        \"],[\"\\\\\\n          SELECT\\n              last_update IS NOT NULL AS initialized,\\n              end_cursor AS endCursor\\n          FROM connections\\n          WHERE object_id = :objectId AND fieldname = :fieldname\\n        \"]))))// No need to worry about corruption in the form of multiple\n// matches: there is a UNIQUE(object_id, fieldname) constraint.\n.get({objectId,fieldname});if(result===undefined){const s=JSON.stringify;throw new Error(\"No such connection: \".concat(s(objectId),\".\").concat(s(fieldname)));}return result.initialized?result.endCursor:undefined;}/**\n   * Create a GraphQL selection set to fetch elements from a collection,\n   * specified by its enclosing object type and the connection field\n   * name (for instance, \"Repository\" and \"issues\").\n   *\n   * If the connection has been queried before and you wish to fetch new\n   * elements, use an appropriate end cursor. Use `undefined` otherwise.\n   * Note that `null` is a valid end cursor and is distinct from\n   * `undefined`. Note that these semantics are compatible with the\n   * return value of `_getEndCursor`.\n   *\n   * If an end cursor for a particular node's connection was specified,\n   * then the resulting GraphQL should be embedded in the context of\n   * that node. For instance, if repository \"foo/bar\" has ID \"baz\" and\n   * an end cursor of \"c000\" on its \"issues\" connection, then the\n   * GraphQL emitted by `_queryConnection(\"issues\", \"c000\")` might\n   * replace the `?` in the following query:\n   *\n   *     node(id: \"baz\") { ? }\n   *\n   * If no end cursor was specified, then the resulting GraphQL may be\n   * embedded in the context of _any_ node with a connection of the\n   * appropriate fieldname. For instance, `_queryConnection(\"issues\")`\n   * emits GraphQL that may replace the `?` in either of the following\n   * queries:\n   *\n   *     node(id: \"baz\") { ? }  # where \"baz\" is a repository ID\n   *     repository(owner: \"foo\", name: \"bar\") { ? }\n   *\n   * Note, however, that this query will fetch nodes from the _start_ of\n   * the connection. It would be wrong to append these results onto an\n   * connection for which we have already fetched data.\n   *\n   * The result of this query has type `ConnectionFieldResult`.\n   *\n   * This function is pure: it does not interact with the database.\n   *\n   * See: `_getEndCursor`.\n   * See: `_updateConnection`.\n   */_queryConnection(typename,fieldname,endCursor,connectionPageSize){if(this._schema[typename]==null){throw new Error(\"No such type: \"+JSON.stringify(typename));}if(this._schema[typename].type!==\"OBJECT\"){const s=JSON.stringify;throw new Error(\"Cannot query connection on non-object type \".concat(s(typename),\" \")+\"(\".concat(this._schema[typename].type,\")\"));}const field=this._schemaInfo.objectTypes[typename].fields[fieldname];if(field==null){const s=JSON.stringify;throw new Error(\"Object type \".concat(s(typename),\" has no field \").concat(s(fieldname)));}if(field.type!==\"CONNECTION\"){const s=JSON.stringify;throw new Error(\"Cannot query non-connection field \".concat(s(typename),\".\").concat(s(fieldname),\" \")+\"(\".concat(field.type,\")\"));}const b=_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"];const connectionArguments={first:b.literal(connectionPageSize)};if(endCursor!==undefined){connectionArguments.after=b.literal(endCursor);}return[b.field(fieldname,connectionArguments,[b.field(\"totalCount\"),b.field(\"pageInfo\",{},[b.field(\"endCursor\"),b.field(\"hasNextPage\")]),b.field(\"nodes\",{},this._queryShallow(field.elementType,field.fidelity))])];}/**\n   * Ingest new entries in a connection on an existing object.\n   *\n   * The connection's last update will be set to the given value, which\n   * must be an existing update lest an error be thrown.\n   *\n   * If the object does not exist or does not have a connection by the\n   * given name, an error will be thrown.\n   *\n   * See: `_queryConnection`.\n   * See: `_createUpdate`.\n   */_updateConnection(updateId,objectId,fieldname,queryResult){this._db.transaction(()=>{this._nontransactionallyUpdateConnection(updateId,objectId,fieldname,queryResult);})();}/**\n   * As `_updateConnection`, but do not enter any transactions. Other\n   * methods may call this method as a subroutine in a larger\n   * transaction.\n   */_nontransactionallyUpdateConnection(updateId,objectId,fieldname,queryResult){const db=this._db;const connectionId=this._db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject25||(_templateObject25=_taggedTemplateLiteral([\"          SELECT rowid FROM connections\\n          WHERE object_id = :objectId AND fieldname = :fieldname\\n        \"],[\"\\\\\\n          SELECT rowid FROM connections\\n          WHERE object_id = :objectId AND fieldname = :fieldname\\n        \"])))).pluck().get({objectId,fieldname});// There is a UNIQUE(object_id, fieldname) constraint, so we don't\n// have to worry about pollution due to duplicates. But it's\n// possible that no such connection exists, indicating that the\n// object has not been registered. This is an error.\nif(connectionId===undefined){const s=JSON.stringify;throw new Error(\"No such connection: \".concat(s(objectId),\".\").concat(s(fieldname)));}db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject26||(_templateObject26=_taggedTemplateLiteral([\"          UPDATE connections\\n          SET\\n              last_update = :updateId,\\n              total_count = :totalCount,\\n              has_next_page = :hasNextPage,\\n              end_cursor = :endCursor\\n          WHERE rowid = :connectionId\\n        \"],[\"\\\\\\n          UPDATE connections\\n          SET\\n              last_update = :updateId,\\n              total_count = :totalCount,\\n              has_next_page = :hasNextPage,\\n              end_cursor = :endCursor\\n          WHERE rowid = :connectionId\\n        \"])))).run({updateId,totalCount:queryResult.totalCount,hasNextPage:+queryResult.pageInfo.hasNextPage,endCursor:queryResult.pageInfo.endCursor,connectionId});let nextIndex=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject27||(_templateObject27=_taggedTemplateLiteral([\"          SELECT IFNULL(MAX(idx), 0) + 1 FROM connection_entries\\n          WHERE connection_id = :connectionId\\n        \"],[\"\\\\\\n          SELECT IFNULL(MAX(idx), 0) + 1 FROM connection_entries\\n          WHERE connection_id = :connectionId\\n        \"])))).pluck().get({connectionId});const addEntry=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject28||(_templateObject28=_taggedTemplateLiteral([\"        INSERT INTO connection_entries (connection_id, idx, child_id)\\n        VALUES (:connectionId, :idx, :childId)\\n      \"],[\"\\\\\\n        INSERT INTO connection_entries (connection_id, idx, child_id)\\n        VALUES (:connectionId, :idx, :childId)\\n      \"]))));for(const node of queryResult.nodes){const childId=this._nontransactionallyRegisterNodeFieldResult(node,()=>{const s=JSON.stringify;return\"when processing \"+\"\".concat(s(fieldname),\" connection of object \").concat(s(objectId));});const idx=nextIndex++;addEntry.run({connectionId,idx,childId});}}/**\n   * Create a GraphQL selection set required to fetch the own-data\n   * (primitives and node references) of an object, but not its\n   * connection entries. The result depends only on the (concrete) type\n   * of the object, not its ID.\n   *\n   * The provided typename must correspond to an object type, not a\n   * union type; otherwise, an error will be thrown.\n   *\n   * The resulting GraphQL can be embedded into the context of any node\n   * with the provided typename. For instance, if there are issues with\n   * IDs \"#1\" and \"#2\", then `_queryOwnData(\"Issue\")` emits GraphQL\n   * that may replace the `?` in any of the following queries:\n   *\n   *     repository(owner: \"foo\", name: \"bar\") {\n   *       issues(first: 1) { ? }\n   *     }\n   *     nodes(ids: [\"#1\", \"#2\") { ... on Issue { ? } }\n   *     node(id: \"#1\") { ... on Issue { ? } }\n   *\n   * The result of this query has type `E`, where `E` is the element\n   * type of `OwnDataUpdateResult`. That is, it is an object with shape\n   * that depends on the provided typename: the name of each ID or\n   * primitive field is a key mapping to a primitive value, and the name\n   * of each node field is a key mapping to a `NodeFieldResult`.\n   * Additionally, the attribute \"__typename\" maps to the node's\n   * typename.\n   *\n   * This function is pure: it does not interact with the database.\n   */_queryOwnData(typename){const type=this._schema[typename];if(type==null){throw new Error(\"No such type: \".concat(JSON.stringify(typename)));}if(type.type!==\"OBJECT\"){throw new Error(\"Not an object type: \".concat(JSON.stringify(typename),\" (\").concat(type.type,\")\"));}const b=_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"];return[b.field(\"__typename\"),...Object.keys(type.fields).map(fieldname=>{const field=type.fields[fieldname];switch(field.type){case\"ID\":return b.field(fieldname);case\"PRIMITIVE\":return b.field(fieldname);case\"NODE\":return b.field(fieldname,{},this._queryShallow(field.elementType,field.fidelity));case\"CONNECTION\":// Not handled by this function.\nreturn null;case\"NESTED\":return b.field(fieldname,{},Object.keys(field.eggs).map(childFieldname=>{const childField=field.eggs[childFieldname];switch(childField.type){case\"PRIMITIVE\":return b.field(childFieldname);case\"NODE\":return b.field(childFieldname,{},this._queryShallow(childField.elementType,childField.fidelity));// istanbul ignore next\ndefault:throw new Error(childField.type);}}));// istanbul ignore next\ndefault:throw new Error(field.type);}}).filter(Boolean)];}/**\n   * Ingest own-data (primitive and link) updates for many objects of a\n   * fixed concrete type. Every object in the input list must have the\n   * same `__typename` attribute, which must be the name of a valid\n   * object type.\n   *\n   * See: `_queryOwnData`.\n   */_updateOwnData(updateId,queryResult){this._db.transaction(()=>{this._nontransactionallyUpdateOwnData(updateId,queryResult);})();}/**\n   * As `_updateOwnData`, but do not enter any transactions. Other\n   * methods may call this method as a subroutine in a larger\n   * transaction.\n   */_nontransactionallyUpdateOwnData(updateId,queryResult){if(queryResult.length===0){return;}const typename=queryResult[0].__typename;if(this._schema[typename]==null){throw new Error(\"Unknown type: \"+JSON.stringify(typename));}if(this._schema[typename].type!==\"OBJECT\"){throw new Error(\"Cannot update data for non-object type: \"+\"\".concat(JSON.stringify(typename),\" (\").concat(this._schema[typename].type,\")\"));}const db=this._db;const objectType=this._schemaInfo.objectTypes[typename];// First, make sure that all objects for which we're given own data\n// actually exist and have the correct typename.\n{const checkTypename=db.prepare(\"SELECT typename IS NOT NULL FROM objects WHERE id = ?\").pluck();for(const entry of queryResult){const hasTypename=checkTypename.get(entry.id);if(hasTypename==null){throw new Error(\"Cannot update data for nonexistent node: \"+JSON.stringify(entry.id));}if(!hasTypename){throw new Error(\"Cannot update data before typename known: \"+JSON.stringify(entry.id));}if(entry.__typename!==typename){const s=JSON.stringify;throw new Error(\"Result set has inconsistent typenames: \"+\"\".concat(s(typename),\" vs. \").concat(s(entry.__typename)));}}}// Set each node's `lastUpdate` time.\n{const setLastUpdate=(()=>{const stmt=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject29||(_templateObject29=_taggedTemplateLiteral([\"            UPDATE objects SET last_update = :updateId\\n            WHERE id = :objectId\\n          \"],[\"\\\\\\n            UPDATE objects SET last_update = :updateId\\n            WHERE id = :objectId\\n          \"]))));const update=_makeSingleUpdateFunction(stmt);return objectId=>update({objectId,updateId});})();for(const entry of queryResult){setLastUpdate(entry.id);}}// Update each node's primitive data.\n//\n// (This typedef would be in the following block statement but for\n// facebook/flow#6961.)\n{const parameterNameFor={topLevelField(fieldname){return[\"t\",fieldname].join(\"_\");},nestedField(nestFieldname,eggFieldname){return[\"n\",String(nestFieldname.length),nestFieldname,eggFieldname].join(\"_\");}};const updatePrimitive=_makeSingleUpdateFunction(db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject30||(_templateObject30=_taggedTemplateLiteral([\"            UPDATE primitives\\n            SET value = :value\\n            WHERE object_id = :id AND fieldname = :fieldname\\n          \"],[\"\\\\\\n            UPDATE primitives\\n            SET value = :value\\n            WHERE object_id = :id AND fieldname = :fieldname\\n          \"])))));for(const entry of queryResult){const primitives={id:entry.id};// Add top-level primitives.\nfor(const fieldname of objectType.primitiveFieldNames){const value=entry[fieldname];const primitive=value;if(primitive===undefined){const s=JSON.stringify;throw new Error(\"Missing primitive \".concat(s(fieldname),\" on \").concat(s(entry.id),\" \")+\"of type \".concat(s(typename),\" (got \").concat(primitive,\")\"));}const jsonValue=JSON.stringify(primitive);primitives[parameterNameFor.topLevelField(fieldname)]=jsonValue;updatePrimitive({id:entry.id,fieldname,value:jsonValue});}// Add nested primitives.\nfor(const nestFieldname of objectType.nestedFieldNames){const nestValue=entry[nestFieldname];const topLevelNested=nestValue;if(topLevelNested===undefined){const s=JSON.stringify;throw new Error(\"Missing nested field \"+\"\".concat(s(nestFieldname),\" on \").concat(s(entry.id),\" \")+\"of type \".concat(s(typename),\" (got \").concat(topLevelNested,\")\"));}primitives[parameterNameFor.topLevelField(nestFieldname)]=topLevelNested==null?0:1;updatePrimitive({id:entry.id,fieldname:nestFieldname,value:topLevelNested==null?0:1});const eggFields=objectType.nestedFields[nestFieldname].primitives;for(const eggFieldname of Object.keys(eggFields)){const eggValue=topLevelNested==null?null:topLevelNested[eggFieldname];const primitive=eggValue;if(primitive===undefined){const s=JSON.stringify;throw new Error(\"Missing nested field \"+\"\".concat(s(nestFieldname),\".\").concat(s(eggFieldname),\" \")+\"on \".concat(s(entry.id),\" \")+\"of type \".concat(s(typename),\" (got \").concat(primitive,\")\"));}const jsonValue=JSON.stringify(primitive);primitives[parameterNameFor.nestedField(nestFieldname,eggFieldname)]=jsonValue;updatePrimitive({id:entry.id,fieldname:\"\".concat(nestFieldname,\".\").concat(eggFieldname),value:jsonValue});}}}}// Update each node's links.\n{const updateLink=(()=>{const stmt=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject31||(_templateObject31=_taggedTemplateLiteral([\"            UPDATE links SET child_id = :childId\\n            WHERE parent_id = :parentId AND fieldname = :fieldname\\n          \"],[\"\\\\\\n            UPDATE links SET child_id = :childId\\n            WHERE parent_id = :parentId AND fieldname = :fieldname\\n          \"]))));return _makeSingleUpdateFunction(stmt);})();for(const entry of queryResult){// Add top-level links.\nfor(const fieldname of objectType.linkFieldNames){const value=entry[fieldname];const link=value;if(link===undefined){const s=JSON.stringify;throw new Error(\"Missing node reference \".concat(s(fieldname),\" on \").concat(s(entry.id),\" \")+\"of type \".concat(s(typename),\" (got \").concat(link,\")\"));}const parentId=entry.id;const childId=this._nontransactionallyRegisterNodeFieldResult(link,()=>\"when setting \"+\"\".concat(typename,\"[\").concat(JSON.stringify(parentId),\"].\").concat(fieldname));updateLink({parentId,fieldname,childId});}// Add nested links.\nfor(const nestFieldname of objectType.nestedFieldNames){const nestValue=entry[nestFieldname];const topLevelNested=nestValue;// No need for an extra safety check that this is present: we\n// handled that while covering primitive fields.\nconst childFields=objectType.nestedFields[nestFieldname].nodes;for(const childFieldname of Object.keys(childFields)){const childValue=topLevelNested==null?null:topLevelNested[childFieldname];const link=childValue;if(link===undefined){const s=JSON.stringify;throw new Error(\"Missing nested field \"+\"\".concat(s(nestFieldname),\".\").concat(s(childFieldname),\" \")+\"on \".concat(s(entry.id),\" \")+\"of type \".concat(s(typename),\" (got \").concat(link,\")\"));}const fieldname=\"\".concat(nestFieldname,\".\").concat(childFieldname);const parentId=entry.id;const childId=this._nontransactionallyRegisterNodeFieldResult(link,()=>\"when setting \"+\"\".concat(typename,\"[\").concat(JSON.stringify(parentId),\"].\").concat(fieldname));updateLink({parentId,fieldname,childId});}}}}// Last-updates, primitives, and links all updated: we're done.\n}/**\n   * Create a GraphQL selection set required to fetch the typename of an\n   * object. The resulting GraphQL can be embedded in any node context.\n   *\n   * The result of this query has type `E`, where `E` is the element\n   * type of `TypenamesUpdateResult`.\n   *\n   * This function is pure: it does not interact with the database.\n   */_queryTypename(){const b=_queries__WEBPACK_IMPORTED_MODULE_6__[\"build\"];return[b.field(\"__typename\"),b.field(\"id\")];}/**\n   * Ingest typenames for many object IDs.\n   *\n   * See: `_queryTypenames`.\n   */_updateTypenames(queryResult){this._db.transaction(()=>{this._nontransactionallyUpdateTypenames(queryResult);})();}/**\n   * As `_updateTypenames`, but do not enter any transactions. Other\n   * methods may call this method as a subroutine in a larger\n   * transaction.\n   */_nontransactionallyUpdateTypenames(queryResult){for(const datum of queryResult){// Need to go through `registerObject` to ensure that primitives,\n// links, and connections are initialized.\nthis._nontransactionallyRegisterObject({id:datum.id,typename:datum.__typename});}}/**\n   * Extract a structured object and all of its transitive dependencies\n   * from the database.\n   *\n   * The result is an object whose keys are fieldnames, and whose values\n   * are:\n   *\n   *   - for \"__typename\": the object's GraphQL typename;\n   *   - for \"id\": the object's GraphQL ID;\n   *   - for primitive fields: the corresponding primitive value;\n   *   - for node reference fields: a reference to the corresponding\n   *     extracted object, which may be `null`;\n   *   - for connection fields: an in-order array of the corresponding\n   *     extracted objects, each of which may be `null`;\n   *   - for nested fields: an object with primitive and node reference\n   *     fields in the same form as above (note: nested objects do not\n   *     automatically have a \"__typename\" field).\n   *\n   * For instance, the result of `extract(\"issue:1\")` might be:\n   *\n   *     {\n   *       __typename: \"Issue\",\n   *       id: \"issue:1172\",\n   *       title: \"bug: holding <Space> causes CPU to overheat\",\n   *       body: \"We should fix this immediately.\",\n   *       author: {\n   *         __typename: \"User\",\n   *         id: \"user:admin\",\n   *         login: \"admin\",\n   *       },\n   *       comments: [\n   *         {\n   *           __typename: \"IssueComment\",\n   *           body: \"I depend on this behavior; please do not change it.\",\n   *           author: {\n   *             __typename: \"User\",\n   *             id: \"user:longtimeuser4\",\n   *             login: \"longtimeuser4\",\n   *           },\n   *         },\n   *         {\n   *           __typename: \"IssueComment\",\n   *           body: \"That's horrifying.\",\n   *           author: {\n   *             __typename: \"User\",\n   *             id: \"user:admin\",\n   *             login: \"admin\",\n   *           },\n   *         },\n   *       ],\n   *       timeline: [\n   *         {\n   *           __typename: \"Commit\",\n   *           messageHeadline: \"reinstate CPU warmer (fixes #1172)\",\n   *           author: {\n   *             date: \"2001-02-03T04:05:06-07:00\",\n   *             user: {\n   *               __typename: \"User\",\n   *               id: \"user:admin\",\n   *               login: \"admin\",\n   *             }\n   *           }\n   *         }\n   *       ],\n   *     }\n   *\n   * (Here, \"title\" is a primitive, the \"author\" field on an issue is a\n   * node reference, \"comments\" is a connection, and the \"author\" field\n   * on a commit is a nested object.)\n   *\n   * The returned structure may be circular.\n   *\n   * If a node appears more than one time in the result---for instance,\n   * the \"user:admin\" node above---all instances will refer to the same\n   * object. However, objects are distinct across calls to `extract`, so\n   * it is safe to deeply mutate the result of this function.\n   *\n   * The provided object ID must correspond to a known object, or an\n   * error will be thrown. Furthermore, all transitive dependencies of\n   * the object must have been at least partially loaded at some point,\n   * or an error will be thrown.\n   */extract(rootId){const db=this._db;return db.transaction(()=>{// Pre-compute transitive dependencies into a temporary table.\ndb.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject32||(_templateObject32=_taggedTemplateLiteral([\"          CREATE TEMPORARY TABLE transitive_dependencies (\\n              id TEXT NOT NULL PRIMARY KEY,\\n              typename TEXT NOT NULL\\n          )\\n        \"],[\"\\\\\\n          CREATE TEMPORARY TABLE transitive_dependencies (\\n              id TEXT NOT NULL PRIMARY KEY,\\n              typename TEXT NOT NULL\\n          )\\n        \"])))).run();try{db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject33||(_templateObject33=_taggedTemplateLiteral([\"            WITH RECURSIVE\\n            cte_direct_deps (parent_id, child_id) AS (\\n                SELECT parent_id, child_id FROM links\\n                WHERE child_id IS NOT NULL\\n                UNION\\n                SELECT DISTINCT\\n                    connections.object_id AS parent_id,\\n                    connection_entries.child_id AS child_id\\n                FROM connections JOIN connection_entries\\n                ON connections.rowid = connection_entries.connection_id\\n                WHERE child_id IS NOT NULL\\n            ),\\n            cte_transitive_deps (id) AS (\\n                VALUES (:rootId) UNION\\n                SELECT cte_direct_deps.child_id\\n                FROM cte_transitive_deps JOIN cte_direct_deps\\n                ON cte_transitive_deps.id = cte_direct_deps.parent_id\\n            )\\n            INSERT INTO transitive_dependencies (id, typename)\\n            SELECT objects.id AS id, objects.typename AS typename\\n            FROM objects JOIN cte_transitive_deps\\n            ON objects.id = cte_transitive_deps.id\\n          \"],[\"\\\\\\n            WITH RECURSIVE\\n            cte_direct_deps (parent_id, child_id) AS (\\n                SELECT parent_id, child_id FROM links\\n                WHERE child_id IS NOT NULL\\n                UNION\\n                SELECT DISTINCT\\n                    connections.object_id AS parent_id,\\n                    connection_entries.child_id AS child_id\\n                FROM connections JOIN connection_entries\\n                ON connections.rowid = connection_entries.connection_id\\n                WHERE child_id IS NOT NULL\\n            ),\\n            cte_transitive_deps (id) AS (\\n                VALUES (:rootId) UNION\\n                SELECT cte_direct_deps.child_id\\n                FROM cte_transitive_deps JOIN cte_direct_deps\\n                ON cte_transitive_deps.id = cte_direct_deps.parent_id\\n            )\\n            INSERT INTO transitive_dependencies (id, typename)\\n            SELECT objects.id AS id, objects.typename AS typename\\n            FROM objects JOIN cte_transitive_deps\\n            ON objects.id = cte_transitive_deps.id\\n          \"])))).run({rootId});// Check to make sure all required objects and connections have\n// been updated at least once.\n{const neverUpdatedEntry=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject34||(_templateObject34=_taggedTemplateLiteral([\"                SELECT objects.id AS id, NULL as fieldname\\n                FROM transitive_dependencies\\n                JOIN objects USING (id)\\n                WHERE objects.last_update IS NULL\\n                UNION ALL\\n                SELECT objects.id AS id, connections.fieldname AS fieldname\\n                FROM transitive_dependencies\\n                JOIN objects\\n                    USING (id)\\n                LEFT OUTER JOIN connections\\n                    ON objects.id = connections.object_id\\n                WHERE\\n                    connections.rowid IS NOT NULL\\n                    AND connections.last_update IS NULL\\n              \"],[\"\\\\\\n                SELECT objects.id AS id, NULL as fieldname\\n                FROM transitive_dependencies\\n                JOIN objects USING (id)\\n                WHERE objects.last_update IS NULL\\n                UNION ALL\\n                SELECT objects.id AS id, connections.fieldname AS fieldname\\n                FROM transitive_dependencies\\n                JOIN objects\\n                    USING (id)\\n                LEFT OUTER JOIN connections\\n                    ON objects.id = connections.object_id\\n                WHERE\\n                    connections.rowid IS NOT NULL\\n                    AND connections.last_update IS NULL\\n              \"])))).get();if(neverUpdatedEntry!==undefined){const entry=neverUpdatedEntry;const s=JSON.stringify;const missingData=entry.fieldname==null?\"own data\":\"\".concat(s(entry.fieldname),\" connection\");throw new Error(\"\".concat(s(rootId),\" transitively depends on \").concat(s(entry.id),\", \")+\"but that object's \".concat(missingData,\" has never been fetched\"));}}// Constructing the result set inherently requires mutation,\n// because the object graph can have cycles. We start by\n// creating a record for each object, with just that object's\n// typename and ID. Then, we link in primitives, node\n// references, and connection entries.\nconst allObjects=new Map();// Initialize `allObjects`.\n{const getObjects=db.prepare(\"SELECT id AS id, typename AS typename FROM transitive_dependencies\");for(const object of getObjects.iterate()){allObjects.set(object.id,{id:object.id,__typename:object.typename});}}// Fill in primitive data.\n{const getPrimitives=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject35||(_templateObject35=_taggedTemplateLiteral([\"              SELECT\\n                object_id AS objectId,\\n                fieldname AS name,\\n                value AS value\\n              FROM transitive_dependencies JOIN primitives\\n              ON transitive_dependencies.id = primitives.object_id\\n              -- Order by field name to ensure that nested fields appear\\n              -- before their eggs: e.g., \\\"author\\\" before \\\"author.user\\\".\\n              ORDER BY fieldname ASC\\n            \"],[\"\\\\\\n              SELECT\\n                object_id AS objectId,\\n                fieldname AS name,\\n                value AS value\\n              FROM transitive_dependencies JOIN primitives\\n              ON transitive_dependencies.id = primitives.object_id\\n              -- Order by field name to ensure that nested fields appear\\n              -- before their eggs: e.g., \\\"author\\\" before \\\"author.user\\\".\\n              ORDER BY fieldname ASC\\n            \"]))));for(const field of getPrimitives.iterate()){const object=_util_null__WEBPACK_IMPORTED_MODULE_4__[\"get\"](allObjects.get(field.objectId));if(field.value===0){// Nested object is absent.\nobject[field.name]=null;}else if(field.value===1){// Nested object is present.\nobject[field.name]={};}else{// Normal field, not nested object indicator.\nconst value=JSON.parse(field.value);const parts=field.name.split(\".\");switch(parts.length){case 1:object[field.name]=value;break;case 2:{const[nestName,eggName]=parts;if(object[nestName]!==null){object[nestName][eggName]=value;}break;}// istanbul ignore next: should not be possible\ndefault:throw new Error(\"Corruption: bad field name: \".concat(JSON.stringify(field.name)));}}}}// Add links.\n{const getLinks=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject36||(_templateObject36=_taggedTemplateLiteral([\"              SELECT\\n                parent_id AS parentId,\\n                fieldname AS fieldname,\\n                child_id AS childId\\n              FROM transitive_dependencies JOIN links\\n              ON transitive_dependencies.id = links.parent_id\\n            \"],[\"\\\\\\n              SELECT\\n                parent_id AS parentId,\\n                fieldname AS fieldname,\\n                child_id AS childId\\n              FROM transitive_dependencies JOIN links\\n              ON transitive_dependencies.id = links.parent_id\\n            \"]))));for(const link of getLinks.iterate()){const parent=_util_null__WEBPACK_IMPORTED_MODULE_4__[\"get\"](allObjects.get(link.parentId));const child=link.childId==null?null:_util_null__WEBPACK_IMPORTED_MODULE_4__[\"get\"](allObjects.get(link.childId));const{fieldname}=link;const parts=fieldname.split(\".\");switch(parts.length){case 1:parent[fieldname]=child;break;case 2:{const[nestName,eggName]=parts;if(parent[nestName]!==null){parent[nestName][eggName]=child;}break;}// istanbul ignore next: should not be possible\ndefault:throw new Error(\"Corruption: bad link name: \".concat(JSON.stringify(fieldname)));}}}// Add connections.\n{const getConnectionData=db.prepare(Object(_util_dedent__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(_templateObject37||(_templateObject37=_taggedTemplateLiteral([\"              SELECT\\n                  objects.id AS parentId,\\n                  connections.fieldname AS fieldname,\\n                  connection_entries.connection_id IS NOT NULL AS hasContents,\\n                  connection_entries.child_id AS childId\\n              FROM transitive_dependencies\\n              JOIN objects\\n                  USING (id)\\n              JOIN connections\\n                  ON objects.id = connections.object_id\\n              LEFT OUTER JOIN connection_entries\\n                  ON connections.rowid = connection_entries.connection_id\\n              ORDER BY\\n                  objects.id, connections.fieldname, connection_entries.idx ASC\\n            \"],[\"\\\\\\n              SELECT\\n                  objects.id AS parentId,\\n                  connections.fieldname AS fieldname,\\n                  connection_entries.connection_id IS NOT NULL AS hasContents,\\n                  connection_entries.child_id AS childId\\n              FROM transitive_dependencies\\n              JOIN objects\\n                  USING (id)\\n              JOIN connections\\n                  ON objects.id = connections.object_id\\n              LEFT OUTER JOIN connection_entries\\n                  ON connections.rowid = connection_entries.connection_id\\n              ORDER BY\\n                  objects.id, connections.fieldname, connection_entries.idx ASC\\n            \"]))));for(const datum of getConnectionData.iterate()){const parent=_util_null__WEBPACK_IMPORTED_MODULE_4__[\"get\"](allObjects.get(datum.parentId));if(parent[datum.fieldname]===undefined){parent[datum.fieldname]=[];}if(datum.hasContents){const child=datum.childId==null?null:_util_null__WEBPACK_IMPORTED_MODULE_4__[\"get\"](allObjects.get(datum.childId));parent[datum.fieldname].push(child);}}}const result=allObjects.get(rootId);if(result===undefined){throw new Error(\"No such object: \"+JSON.stringify(rootId));}return result;}finally{this._db.prepare(\"DROP TABLE temp.transitive_dependencies\").run();}})();}}/**\n * Decomposition of a schema, grouping types by their kind (object vs.\n * union) and object fields by their kind (primitive vs. link vs.\n * connection).\n *\n * All arrays contain elements in arbitrary order.\n */function _buildSchemaInfo(schema){const result={objectTypes:{},unionTypes:{}};for(const typename of Object.keys(schema)){const type=schema[typename];switch(type.type){case\"SCALAR\":// Nothing to do.\nbreak;case\"ENUM\":// Nothing to do.\nbreak;case\"OBJECT\":{const entry={fields:type.fields,nestedFields:{},primitiveFieldNames:[],linkFieldNames:[],connectionFieldNames:[],nestedFieldNames:[]};result.objectTypes[typename]=entry;for(const fieldname of Object.keys(type.fields)){const field=type.fields[fieldname];switch(field.type){case\"ID\":break;case\"PRIMITIVE\":entry.primitiveFieldNames.push(fieldname);break;case\"NODE\":entry.linkFieldNames.push(fieldname);break;case\"CONNECTION\":entry.connectionFieldNames.push(fieldname);break;case\"NESTED\":{entry.nestedFieldNames.push(fieldname);const nestedFieldData={primitives:{},nodes:{}};for(const eggFieldname of Object.keys(field.eggs)){const eggField=field.eggs[eggFieldname];switch(eggField.type){case\"PRIMITIVE\":nestedFieldData.primitives[eggFieldname]=eggField;break;case\"NODE\":nestedFieldData.nodes[eggFieldname]=eggField;break;// istanbul ignore next\ndefault:throw new Error(eggField.type);}}entry.nestedFields[fieldname]=nestedFieldData;break;}// istanbul ignore next\ndefault:throw new Error(field.type);}}break;}case\"UNION\":{const entry={clauses:Object.keys(type.clauses)};result.unionTypes[typename]=entry;break;}// istanbul ignore next\ndefault:throw new Error(type.type);}}return result;}const _FIELD_PREFIXES=deep_freeze__WEBPACK_IMPORTED_MODULE_0___default()({/**\n   * A key of an `UpdateResult` has this prefix if and only if the\n   * corresponding value represents `TypenamesUpdateResult`s.\n   */TYPENAMES:\"typenames_\",/**\n   * A key of an `UpdateResult` has this prefix if and only if the\n   * corresponding value represents `OwnDataUpdateResult`s.\n   */OWN_DATA:\"owndata_\",/**\n   * A key of an `UpdateResult` has this prefix if and only if the\n   * corresponding value represents `NodeConnectionsUpdateResult`s.\n   */NODE_CONNECTIONS:\"node_\"});/**\n * Convert a prepared statement into a JS function that executes that\n * statement and asserts that it makes exactly one change to the\n * database.\n *\n * The prepared statement must use only named parameters, not positional\n * parameters.\n *\n * The prepared statement must not return data (e.g., INSERT and UPDATE\n * are okay; SELECT is not).\n *\n * The statement is not executed inside an additional transaction, so in\n * the case that the assertion fails, the effects of the statement are\n * not rolled back by this function.\n *\n * This is useful when the statement is like `UPDATE ... WHERE id = ?`\n * and it is assumed that `id` is a primary key for a record already\n * exists---if either existence or uniqueness fails, this method will\n * raise an error quickly instead of leading to a corrupt state.\n *\n * For example, this code...\n *\n *     const setName: ({|+userId: string, +newName: string|}) => void =\n *       _makeSingleUpdateFunction(\n *         \"UPDATE users SET name = :newName WHERE id = :userId\"\n *       );\n *     setName({userId: \"user:foo\", newName: \"The Magnificent Foo\"});\n *\n * ...will update `user:foo`'s name, or throw an error if there is no\n * such user or if multiple users have this ID.\n */function _makeSingleUpdateFunction(stmt){if(stmt.reader){throw new Error(\"Cannot create update function for statement that returns data: \"+stmt.source);}return args=>{const result=stmt.run(args);if(result.changes!==1){throw new Error(\"Bad change count: \"+JSON.stringify({source:stmt.source,args,changes:result.changes}));}};}\n\n//# sourceURL=webpack:///./src/graphql/mirror.js?");

/***/ }),

/***/ "./src/graphql/queries.js":
/*!********************************!*\
  !*** ./src/graphql/queries.js ***!
  \********************************/
/*! exports provided: build, multilineLayout, inlineLayout, stringify */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"build\", function() { return build; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"multilineLayout\", function() { return multilineLayout; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"inlineLayout\", function() { return inlineLayout; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stringify\", function() { return stringify; });\n/**\n * GraphQL structured query data format.\n *\n * Main module exports:\n *   - lots of types for various GraphQL language constructs\n *   - the `build` object, providing a fluent builder API\n *   - the `stringify` object, and particularly `stringify.body`\n *   - the two layout strategies `multilineLayout` and `inlineLayout`\n */ // We only need opaque type handles; no need to embed the GraphQL type\n// system into Flow.\nconst build={query(name,params,selections){return{type:\"QUERY\",name,params,selections};},param(name,type){return{name,type};},fragment(name,typeCondition,selections){return{type:\"FRAGMENT\",name,typeCondition,selections};},field(name,args,selections){return{type:\"FIELD\",alias:null,name,args:args||{},selections:selections||[]};},alias(newAlias,field){return{type:\"FIELD\",alias:newAlias,name:field.name,args:field.args,selections:field.selections};},fragmentSpread(fragmentName){return{type:\"FRAGMENT_SPREAD\",fragmentName};},inlineFragment(typeCondition,selections){return{type:\"INLINE_FRAGMENT\",typeCondition,selections};},variable(name){return{type:\"VARIABLE\",data:name};},literal(value){return{type:\"LITERAL\",data:value};},enumLiteral(value){return{type:\"ENUM\",data:value};},list(data){return{type:\"LIST\",data:data};},object(data){return{type:\"OBJECT\",data:data};}};/**\n * A strategy for stringifying a sequence of GraphQL language tokens.\n */ /**\n * Create a layout strategy that lays out text over multiple lines,\n * indenting with the given tab string (such as \"\\t\" or \"  \").\n */function multilineLayout(tab){function strategy(indentLevel){return{atom:line=>{const indentation=Array(indentLevel).fill(tab).join(\"\");return indentation+line;},join:xs=>xs.join(\"\\n\"),next:()=>strategy(indentLevel+1)};}return strategy(0);}/**\n * Create a layout strategy that lays out all text on one line.\n */function inlineLayout(){const result={atom:line=>line,join:xs=>xs.join(\" \"),next:()=>result};return result;}/*\n * Map a stringification function across a list, and join the results\n * with a formatter.\n */function formatList(values,subformatter,ls){return ls.join(values.map(x=>subformatter(x,ls)));}/*\n * Map a stringification function across the values of an object, and\n * join the keys and their corresponding results with a formatter.\n */function formatObject(object,subformatter,ls){function formatKey(k,ls){return ls.join([ls.atom(\"\".concat(k,\":\")),subformatter(object[k],ls.next())]);}return formatList(Object.keys(object),formatKey,ls);}const stringify={body(body,ls){return formatList(body,stringify.definition,ls);},definition(definition,ls){switch(definition.type){case\"QUERY\":return stringify.queryDefinition(definition,ls);case\"FRAGMENT\":return stringify.fragmentDefinition(definition,ls);// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(\"Unknown definition type: \".concat(definition.type));}},queryDefinition(query,ls){const paramsPart=(()=>{if(query.params.length===0){return\"\";}else{const items=formatList(query.params,stringify.parameter,inlineLayout());return\"(\".concat(items,\")\");}})();const selectionsPart=formatList(query.selections,stringify.selection,ls.next());return ls.join([ls.atom(\"query \".concat(query.name).concat(paramsPart,\" {\")),selectionsPart,ls.atom(\"}\")]);},parameter(parameter,ls){return ls.atom(\"$\".concat(parameter.name,\": \").concat(parameter.type));},fragmentDefinition(fragment,ls){const selectionsPart=formatList(fragment.selections,stringify.selection,ls.next());return ls.join([ls.atom(\"fragment \".concat(fragment.name,\" on \").concat(fragment.typeCondition,\" {\")),selectionsPart,ls.atom(\"}\")]);},selection(selection,ls){switch(selection.type){case\"FIELD\":return stringify.field(selection,ls);case\"FRAGMENT_SPREAD\":return stringify.fragmentSpread(selection,ls);case\"INLINE_FRAGMENT\":return stringify.inlineFragment(selection,ls);// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(\"Unknown selection type: \".concat(selection.type));}},field(field,ls){const aliasPart=(()=>{if(field.alias==null){return\"\";}else{return\"\".concat(field.alias,\": \");}})();const argsPart=(()=>{if(Object.keys(field.args).length===0){return\"\";}else{const args=formatObject(field.args,stringify.value,inlineLayout());return\"(\".concat(args,\")\");}})();if(field.selections.length===0){return ls.atom(\"\".concat(field.name).concat(argsPart));}else{const selectionsPart=formatList(field.selections,stringify.selection,ls.next());return ls.join([ls.atom(\"\".concat(aliasPart).concat(field.name).concat(argsPart,\" {\")),selectionsPart,ls.atom(\"}\")]);}},fragmentSpread(fs,ls){return ls.atom(\"...\".concat(fs.fragmentName));},inlineFragment(fragment,ls){const typeConditionPart=fragment.typeCondition==null?\"\":\" on \".concat(fragment.typeCondition);const selectionsPart=formatList(fragment.selections,stringify.selection,ls.next());return ls.join([ls.atom(\"...\".concat(typeConditionPart,\" {\")),selectionsPart,ls.atom(\"}\")]);},value(value,ls){switch(value.type){case\"VARIABLE\":return stringify.variableValue(value,ls);case\"LITERAL\":return stringify.literalValue(value,ls);case\"ENUM\":return stringify.enumValue(value,ls);case\"LIST\":return stringify.listValue(value,ls);case\"OBJECT\":return stringify.objectValue(value,ls);// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(\"Unknown value type: \".concat(value.type));}},variableValue(value,ls){return ls.atom(\"$\".concat(value.data));},literalValue(value,ls){return ls.atom(JSON.stringify(value.data));},enumValue(value,ls){return ls.atom(value.data);},listValue(value,ls){return ls.join([ls.atom(\"[\"),formatList(value.data,stringify.value,ls.next()),ls.atom(\"]\")]);},objectValue(value,ls){return ls.join([ls.atom(\"{\"),formatObject(value.data,stringify.value,ls.next()),ls.atom(\"}\")]);}};\n\n//# sourceURL=webpack:///./src/graphql/queries.js?");

/***/ }),

/***/ "./src/graphql/schema.js":
/*!*******************************!*\
  !*** ./src/graphql/schema.js ***!
  \*******************************/
/*! exports provided: faithful, unfaithful, schema, scalar, enum, object, union, id, primitive, node, connection, nonNull, nullable, nested */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"faithful\", function() { return faithful; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"unfaithful\", function() { return unfaithful; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"schema\", function() { return schema; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scalar\", function() { return scalar; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enum\", function() { return enum_; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"object\", function() { return object; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"union\", function() { return union; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"id\", function() { return id; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"primitive\", function() { return primitive; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"node\", function() { return node; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"connection\", function() { return connection; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nonNull\", function() { return nonNull; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nullable\", function() { return nullable; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nested\", function() { return nested; });\nfunction ownKeys(object,enumerableOnly){var keys=Object.keys(object);if(Object.getOwnPropertySymbols){var symbols=Object.getOwnPropertySymbols(object);if(enumerableOnly){symbols=symbols.filter(function(sym){return Object.getOwnPropertyDescriptor(object,sym).enumerable;});}keys.push.apply(keys,symbols);}return keys;}function _objectSpread(target){for(var i=1;i<arguments.length;i++){var source=arguments[i]!=null?arguments[i]:{};if(i%2){ownKeys(Object(source),true).forEach(function(key){_defineProperty(target,key,source[key]);});}else if(Object.getOwnPropertyDescriptors){Object.defineProperties(target,Object.getOwnPropertyDescriptors(source));}else{ownKeys(Object(source)).forEach(function(key){Object.defineProperty(target,key,Object.getOwnPropertyDescriptor(source,key));});}}return target;}function _defineProperty(obj,key,value){if(key in obj){Object.defineProperty(obj,key,{value:value,enumerable:true,configurable:true,writable:true});}else{obj[key]=value;}return obj;}/**\n * Data types to describe a particular subset of GraphQL schemata.\n * Schemata represented by this module must satisfy these constraints:\n *\n *   - Every object must have an `id` field of primitive type.\n *   - Every field of an object must be either a primitive, a reference\n *     to a single (possibly nullable) object, or a _connection_ as\n *     described in the Relay cursor connections specification. In\n *     particular, no field may directly contain a list.\n *   - Interface types must be represented as unions of all their\n *     implementations.\n */ // The name of a GraphQL type, like `Repository` or `Int`.\n// The name of a GraphQL object field, like `name` or `pullRequests`.\n// The database-wide unique ID of a GraphQL object.\n// Description of a GraphQL schema. Types are represented as follows:\n//   - An object type is represented directly as an `OBJECT`.\n//   - A union type is represented directly as a `UNION`.\n//   - An interface type is represented as a `UNION` of all its\n//     implementations.\n//   - Scalars and enums may only occur as object fields, and are\n//     represented as `PRIMITIVE`s (except for `ID`s).\n//   - Connections are supported as object fields, but arbitrary lists\n//     are not.\n//\n// Primitive and enum fields on an object type may optionally be\n// annotated with their representations.\n//\n// To accommodate schemata where some object types do not have IDs,\n// objects may have \"nested\" fields of primitive or node-reference type.\n// These may be nested to depth exactly 1. Suppose that `Foo` is an\n// object type that includes `bar: Bar!`, but `Bar` is an object type\n// without an `id`. Then `Bar` may not be a first-class type, but `Foo`\n// may pull properties off of it using\n//\n//     bar: nested({x: primitive(), y: node(\"Baz\")});\n//\n// The property \"bar\" in the above example is called a _nested_\n// property, and its fields \"x\" and \"y\" are called _eggs_. (The nest\n// contains the eggs.)\n// A field is _faithful_ if selecting its `__typename` and `id` will\n// always yield the correct `__typename` for the node of the given ID.\n// In theory, this should always be the case, but some remote schemas\n// are broken. For details, see:\n//\n//   - https://github.com/sourcecred/sourcecred/issues/996\n//   - https://github.com/sourcecred/sourcecred/issues/998\n//\n// For an unfaithful field, the `actualTypenames` property lists all the\n// types of objects that can _actually_ be returned when the field is\n// queried. (This set only affects generated Flow types, not runtime\n// semantics.) These must all be object types.\n//\n// It is always sound to represent an actually-faithful field as\n// unfaithful, but doing so may incur additional queries. Marking a type\n// as faithful should be seen as an optimization that may be performed\n// only when the server is abiding by its contract for that field.\nfunction faithful(){return{type:\"FAITHFUL\"};}function unfaithful(actualTypenames){const actualTypenamesObject={};for(const t of actualTypenames){actualTypenamesObject[t]=true;}return{type:\"UNFAITHFUL\",actualTypenames:actualTypenamesObject};}// Every object must have exactly one `id` field, and it must have this\n// name.\nconst ID_FIELD_NAME=\"id\";function schema(types){function assertKind(path,elementTypename,validKinds){let{isFidelity=false}=arguments.length>3&&arguments[3]!==undefined?arguments[3]:{};const self=(isFidelity?\"unfaithful typenames list of \":\"\")+\"field \".concat(path.map(x=>JSON.stringify(x)).join(\"/\"));const elementType=types[elementTypename];if(elementType==null){throw new Error(\"\".concat(self,\" has unknown type: \\\"\").concat(elementTypename,\"\\\"\"));}if(!validKinds.includes(elementType.type)){throw new Error(\"\".concat(self,\" has invalid type \\\"\").concat(elementTypename,\"\\\" \")+\"of kind \\\"\".concat(elementType.type,\"\\\"\"));}}function validateFidelity(path,fidelity){switch(fidelity.type){case\"FAITHFUL\":break;case\"UNFAITHFUL\":for(const typename of Object.keys(fidelity.actualTypenames)){assertKind(path,typename,[\"OBJECT\"],{isFidelity:true});}break;// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(fidelity.type);}}const result={};for(const typename of Object.keys(types)){const type=types[typename];switch(type.type){case\"SCALAR\":result[typename]={type:\"SCALAR\",representation:type.representation};break;case\"ENUM\":result[typename]={type:\"ENUM\",values:_objectSpread({},type.values)};break;case\"OBJECT\":for(const fieldname of Object.keys(type.fields)){const field=type.fields[fieldname];switch(field.type){case\"ID\":// Nothing to check.\nbreak;case\"PRIMITIVE\":if(field.annotation!=null){assertKind([typename,fieldname],field.annotation.elementType,[\"SCALAR\",\"ENUM\"]);}break;case\"NODE\":assertKind([typename,fieldname],field.elementType,[\"OBJECT\",\"UNION\"]);validateFidelity([typename,fieldname],field.fidelity);break;case\"CONNECTION\":assertKind([typename,fieldname],field.elementType,[\"OBJECT\",\"UNION\"]);validateFidelity([typename,fieldname],field.fidelity);break;case\"NESTED\":for(const eggName of Object.keys(field.eggs)){const egg=field.eggs[eggName];switch(egg.type){case\"PRIMITIVE\":if(egg.annotation!=null){assertKind([typename,fieldname,eggName],egg.annotation.elementType,[\"SCALAR\",\"ENUM\"]);}break;case\"NODE\":assertKind([typename,fieldname,eggName],egg.elementType,[\"OBJECT\",\"UNION\"]);validateFidelity([typename,fieldname,eggName],egg.fidelity);break;// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(egg.type);}}break;// istanbul ignore next: unreachable per Flow\ndefault:throw new Error(field.type);}}result[typename]={type:\"OBJECT\",fields:_objectSpread({},type.fields)};break;case\"UNION\":for(const clause of Object.keys(type.clauses)){const clauseType=types[clause];if(clauseType==null){throw new Error(\"union has unknown clause: \\\"\".concat(typename,\"\\\"/\\\"\").concat(clause,\"\\\"\"));}if(clauseType.type!==\"OBJECT\"){// The GraphQL spec doesn't permit unions of interfaces or\n// other unions (or primitives). This is nice, because it\n// means that we don't have to worry about ill-founded\n// unions.\nthrow new Error(\"union has non-object type clause: \\\"\".concat(typename,\"\\\"/\\\"\").concat(clause,\"\\\"\"));}}result[typename]={type:\"UNION\",clauses:_objectSpread({},type.clauses)};break;// istanbul ignore next\ndefault:throw new Error(type.type);}}return result;}function scalar(representation){return{type:\"SCALAR\",representation};}function enum_(values){const valuesObject={};for(const v of values){valuesObject[v]=true;}return{type:\"ENUM\",values:valuesObject};}function object(fields){for(const fieldname of Object.keys(fields)){const field=fields[fieldname];if(fieldname===\"__typename\"){throw new Error(\"reserved field name: \"+fieldname);}if(field.type===\"ID\"&&fieldname!==ID_FIELD_NAME){throw new Error(\"invalid ID field with name \\\"\".concat(fieldname,\"\\\"\"));}}if(fields[ID_FIELD_NAME]==null){throw new Error(\"expected ID field with name \\\"\".concat(ID_FIELD_NAME,\"\\\"\"));}if(fields[ID_FIELD_NAME].type!==\"ID\"){throw new Error(\"field \\\"\".concat(ID_FIELD_NAME,\"\\\" must be an ID field\"));}// Workaround for <https://github.com/facebook/flow/issues/7128>.\nconst exactFields=_objectSpread({},fields);return{type:\"OBJECT\",fields:exactFields};}function union(clauses){const clausesMap={};for(const clause of clauses){if(clausesMap[clause]!=null){throw new Error(\"duplicate union clause: \\\"\".concat(clause,\"\\\"\"));}clausesMap[clause]=true;}return{type:\"UNION\",clauses:clausesMap};}function id(){return{type:\"ID\"};}function primitive(annotation){return{type:\"PRIMITIVE\",annotation:annotation||null};}function node(elementType){let fidelity=arguments.length>1&&arguments[1]!==undefined?arguments[1]:faithful();return{type:\"NODE\",elementType,fidelity};}function connection(elementType){let fidelity=arguments.length>1&&arguments[1]!==undefined?arguments[1]:faithful();return{type:\"CONNECTION\",elementType,fidelity};}function nonNull(elementType){return{nonNull:true,elementType};}function nullable(elementType){return{nonNull:false,elementType};}function nested(eggs){return{type:\"NESTED\",eggs:_objectSpread({},eggs)};}\n\n//# sourceURL=webpack:///./src/graphql/schema.js?");

/***/ }),

/***/ "./src/plugins/github/bin/fetchAndPrintGithubOrg.js":
/*!**********************************************************!*\
  !*** ./src/plugins/github/bin/fetchAndPrintGithubOrg.js ***!
  \**********************************************************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var json_stable_stringify__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! json-stable-stringify */ \"json-stable-stringify\");\n/* harmony import */ var json_stable_stringify__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(json_stable_stringify__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _fetchGithubOrg__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../fetchGithubOrg */ \"./src/plugins/github/fetchGithubOrg.js\");\n/* harmony import */ var _token__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../token */ \"./src/plugins/github/token.js\");\n/*\n * Command-line utility to fetch GitHub data using the API in\n * ../fetchGithubOrg, and print it to stdout. Useful for testing or\n * saving some data to disk.\n *\n * Usage:\n *\n *   node bin/fetchAndPrintGithubOrg.js ORGANIZATION_NAME GITHUB_TOKEN [PAGE_SIZE]\n *\n * where GITHUB_TOKEN is a GitHub authentication token, as generated\n * from https://github.com/settings/tokens/new.\n */function parseArgs(){const argv=process.argv.slice(2);const fail=()=>{const invocation=process.argv.slice(0,2).join(\" \");throw new Error(\"Usage: \".concat(invocation,\" ORGANIZATION_NAME GITHUB_TOKEN [PAGE_SIZE]\"));};if(argv.length<2){fail();}const[organization,unvalidatedGithubToken,...rest]=argv;let pageSize;if(rest.length===1){pageSize=Number(rest[0]);}const githubToken=Object(_token__WEBPACK_IMPORTED_MODULE_2__[\"validateToken\"])(unvalidatedGithubToken);const result={organization,githubToken,pageSize};if(rest.length>1){fail();}return result;}function main(){const{organization,githubToken,pageSize}=parseArgs();Object(_fetchGithubOrg__WEBPACK_IMPORTED_MODULE_1__[\"fetchGithubOrg\"])(organization,githubToken,pageSize).then(data=>{console.log(json_stable_stringify__WEBPACK_IMPORTED_MODULE_0___default()(data,{space:4}));}).catch(errors=>{console.error(\"Errors processing the result:\");console.error(errors);process.exit(1);});}main();\n\n//# sourceURL=webpack:///./src/plugins/github/bin/fetchAndPrintGithubOrg.js?");

/***/ }),

/***/ "./src/plugins/github/cacheId.js":
/*!***************************************!*\
  !*** ./src/plugins/github/cacheId.js ***!
  \***************************************/
/*! exports provided: cacheIdForRepoId */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cacheIdForRepoId\", function() { return cacheIdForRepoId; });\n/* harmony import */ var _repoId__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./repoId */ \"./src/plugins/github/repoId.js\");\n/**\n * A derived ID to reference a cache layer.\n */ /**\n * Derives the CacheId for a RepoId.\n *\n * Returned `CacheId`s will be:\n * - Deterministic\n * - Unique for this plugin\n * - Lowercase\n * - Safe to use for filenames\n * - Distinct for semantically distinct inputs (input IDs that differ\n *   only in case may map to the same output, because GitHub does not\n *   permit collisions-modulo-case)\n */function cacheIdForRepoId(repoId){// GitHub owner (user/organization) and repository names may be in\n// mixed case, but GitHub prevents mixed-case collisions: e.g., if\n// `foo` is a user then `Foo` cannot also be a user, and likewise for\n// repositories. GitHub login names are DNS-safe (`[0-9A-Za-z-]` only)\n// and so are filename-safe. Repository names have a slightly larger\n// character set, including underscore, but are also filename-safe.\n// Because login may not contain an underscore, it thus suffices to\n// use an underscore as the delimiter. The resulting filename uses\n// only `[0-9A-Za-z_.-]` and so is valid on all major filesystems.\nconst owner=repoId.owner.toLowerCase();const name=repoId.name.toLowerCase();if(owner.includes(\"_\")){throw new Error(\"unexpected underscore in GitHub owner name would be ambiguous: \"+Object(_repoId__WEBPACK_IMPORTED_MODULE_0__[\"repoIdToString\"])(repoId));}return\"github_\".concat(owner,\"_\").concat(name);}\n\n//# sourceURL=webpack:///./src/plugins/github/cacheId.js?");

/***/ }),

/***/ "./src/plugins/github/fetchGithubOrg.js":
/*!**********************************************!*\
  !*** ./src/plugins/github/fetchGithubOrg.js ***!
  \**********************************************/
/*! exports provided: fetchGithubOrg */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchGithubOrg\", function() { return fetchGithubOrg; });\n/* harmony import */ var _repoId__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./repoId */ \"./src/plugins/github/repoId.js\");\n/* harmony import */ var _graphql_queries__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../graphql/queries */ \"./src/graphql/queries.js\");\n/* harmony import */ var _fetchGithubRepo__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fetchGithubRepo */ \"./src/plugins/github/fetchGithubRepo.js\");\nfunction ownKeys(object,enumerableOnly){var keys=Object.keys(object);if(Object.getOwnPropertySymbols){var symbols=Object.getOwnPropertySymbols(object);if(enumerableOnly){symbols=symbols.filter(function(sym){return Object.getOwnPropertyDescriptor(object,sym).enumerable;});}keys.push.apply(keys,symbols);}return keys;}function _objectSpread(target){for(var i=1;i<arguments.length;i++){var source=arguments[i]!=null?arguments[i]:{};if(i%2){ownKeys(Object(source),true).forEach(function(key){_defineProperty(target,key,source[key]);});}else if(Object.getOwnPropertyDescriptors){Object.defineProperties(target,Object.getOwnPropertyDescriptors(source));}else{ownKeys(Object(source)).forEach(function(key){Object.defineProperty(target,key,Object.getOwnPropertyDescriptor(source,key));});}}return target;}function _defineProperty(obj,key,value){if(key in obj){Object.defineProperty(obj,key,{value:value,enumerable:true,configurable:true,writable:true});}else{obj[key]=value;}return obj;}const DEFAULT_PAGE_SIZE=100;/**\n * Fetches information about a given GitHub organization.\n *\n * Currently just gets the ids of its repositories, but we may want additional\n * information in the future.\n */async function fetchGithubOrg(org,token,// Regular clients should leave pageSize at the default 50.\n// Exposed for testing purposes.\npageSize){const numRepos=pageSize==null?DEFAULT_PAGE_SIZE:pageSize;const b=_graphql_queries__WEBPACK_IMPORTED_MODULE_1__[\"build\"];const makePayload=afterCursor=>{const afterArg=afterCursor==null?{}:{after:b.literal(afterCursor)};const args=_objectSpread({query:b.variable(\"searchQuery\"),type:b.enumLiteral(\"REPOSITORY\"),first:b.literal(numRepos)},afterArg);return{body:[b.query(\"PerformSearch\",[b.param(\"searchQuery\",\"String!\")],[b.field(\"search\",args,[b.field(\"nodes\",{},[b.inlineFragment(\"Repository\",[b.field(\"name\"),b.field(\"id\")])]),b.field(\"pageInfo\",{},[b.field(\"endCursor\"),b.field(\"hasNextPage\")])])])],variables:{searchQuery:\"org:\".concat(org)}};};let result=await Object(_fetchGithubRepo__WEBPACK_IMPORTED_MODULE_2__[\"postQuery\"])(makePayload(),token);const resultNodes=[result.search.nodes];while(result.search.pageInfo.hasNextPage){const afterCursor=result.search.pageInfo.endCursor;result=await Object(_fetchGithubRepo__WEBPACK_IMPORTED_MODULE_2__[\"postQuery\"])(makePayload(afterCursor),token);resultNodes.push(result.search.nodes);}const repos=[].concat(...resultNodes).map(n=>Object(_repoId__WEBPACK_IMPORTED_MODULE_0__[\"makeRepoId\"])(org,n.name));return{repos,name:org};}\n\n//# sourceURL=webpack:///./src/plugins/github/fetchGithubOrg.js?");

/***/ }),

/***/ "./src/plugins/github/fetchGithubRepo.js":
/*!***********************************************!*\
  !*** ./src/plugins/github/fetchGithubRepo.js ***!
  \***********************************************/
/*! exports provided: fetchGithubRepoFromCache, default, _guessTypename, _resolveRefreshTime, postQuery */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchGithubRepoFromCache\", function() { return fetchGithubRepoFromCache; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return fetchGithubRepo; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_guessTypename\", function() { return _guessTypename; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_resolveRefreshTime\", function() { return _resolveRefreshTime; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"postQuery\", function() { return postQuery; });\n/* harmony import */ var better_sqlite3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! better-sqlite3 */ \"better-sqlite3\");\n/* harmony import */ var better_sqlite3__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(better_sqlite3__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var isomorphic_fetch__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! isomorphic-fetch */ \"isomorphic-fetch\");\n/* harmony import */ var isomorphic_fetch__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(isomorphic_fetch__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _repoId__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./repoId */ \"./src/plugins/github/repoId.js\");\n/* harmony import */ var _graphql_mirror__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../graphql/mirror */ \"./src/graphql/mirror.js\");\n/* harmony import */ var _graphql_queries__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../graphql/queries */ \"./src/graphql/queries.js\");\n/* harmony import */ var _graphql_schema__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../graphql/schema */ \"./src/graphql/schema.js\");\n/* harmony import */ var _schema__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./schema */ \"./src/plugins/github/schema.js\");\n/* harmony import */ var _cacheId__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./cacheId */ \"./src/plugins/github/cacheId.js\");\n/* harmony import */ var _util_retry__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../util/retry */ \"./src/util/retry.js\");\n/*\n * API to scrape data from a GitHub repo using the GitHub API. See the\n * docstring of the default export for more details.\n *//**\n * Retrieve previously scraped data for a GitHub repo from cache.\n *\n * Note: the GithubToken requirement is planned to be removed.\n * See https://github.com/sourcecred/sourcecred/issues/1580\n *\n * @param {RepoId} repoId\n *    the GitHub repository to retrieve from cache\n * @param {GithubToken} token\n *    authentication token to be used for the GitHub API; generate a\n *    token at: https://github.com/settings/tokens\n * @return {Promise<Repository>}\n *    a promise that resolves to a JSON object containing the data\n *    scraped from the repository, with data format to be specified\n *    later\n */async function fetchGithubRepoFromCache(repoId,_ref){let{token,cache}=_ref;// TODO: remove the need for a GithubToken to resolve the ID.\n// See https://github.com/sourcecred/sourcecred/issues/1580\nconst postQueryWithToken=payload=>postQuery(payload,token);const resolvedId=await resolveRepositoryGraphqlId(postQueryWithToken,repoId);const db=await cache.database(Object(_cacheId__WEBPACK_IMPORTED_MODULE_7__[\"cacheIdForRepoId\"])(repoId));const mirror=new _graphql_mirror__WEBPACK_IMPORTED_MODULE_3__[\"Mirror\"](db,Object(_schema__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(),{guessTypename:_guessTypename});return mirror.extract(resolvedId);}/**\n * Scrape data from a GitHub repo using the GitHub API.\n *\n * @param {RepoId} repoId\n *    the GitHub repository to be scraped\n * @param {GithubToken} token\n *    authentication token to be used for the GitHub API; generate a\n *    token at: https://github.com/settings/tokens\n * @return {Promise<object>}\n *    a promise that resolves to a JSON object containing the data\n *    scraped from the repository, with data format to be specified\n *    later\n */async function fetchGithubRepo(repoId,_ref2){let{token,cache}=_ref2;const postQueryWithToken=payload=>postQuery(payload,token);const resolvedId=await resolveRepositoryGraphqlId(postQueryWithToken,repoId);// Key the cache file against the RepoId, but make sure that the\n// name is valid and uniquely identifying even on case-insensitive\n// filesystems (HFS, HFS+, APFS, NTFS) or filesystems preventing\n// equals signs in file names.\nconst db=await cache.database(Object(_cacheId__WEBPACK_IMPORTED_MODULE_7__[\"cacheIdForRepoId\"])(repoId));const mirror=new _graphql_mirror__WEBPACK_IMPORTED_MODULE_3__[\"Mirror\"](db,Object(_schema__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(),{guessTypename:_guessTypename});mirror.registerObject({typename:\"Repository\",id:resolvedId});// These are arbitrary tuning parameters.\n// TODO(#638): Design a configuration system for plugins.\nconst ttlSeconds=60*60*12;const nodesLimit=100;const connectionLimit=100;await mirror.update(postQueryWithToken,{since:new Date(Date.now()-ttlSeconds*1000),now:()=>new Date(),// These properties are arbitrary tuning parameters.\nnodesLimit,connectionLimit,// These values are the maxima allowed by GitHub.\nnodesOfTypeLimit:100,connectionPageSize:100});return mirror.extract(resolvedId);}// GitHub object IDs are urlsafe-base64-encoded strings that decode to\n// ASCII strings of the form \"123:Typename4567[...]\", where the \"123\"\n// numbers are a function only of the typename and the \"4567\" numbers\n// are the object's database ID, and the \"[...]\" is either empty or a\n// further section like \":commithash\" for commits.\n//\n// See tests for `_guessTypename` for some example object IDs.\nconst GITHUB_ID_TYPENAME_PATTERN=/^[0-9]*:([a-z0-9_-]*[a-z_-])[0-9]+(?:[^a-z0-9_-].*)?$/i;function _guessTypename(objectId){const decodedId=Buffer.from(objectId,\"base64\").toString(\"utf-8\");const match=decodedId.match(GITHUB_ID_TYPENAME_PATTERN);return match?match[1]:null;}const GITHUB_GRAPHQL_SERVER=\"https://api.github.com/graphql\";// Fetch against the GitHub API with the provided options, returning a\n// promise that either resolves to the GraphQL result data or rejects\n// to a `GithubResponseError`.\nfunction tryGithubFetch(postBody,token){const fetchOptions={method:\"POST\",body:postBody,headers:{Authorization:\"bearer \".concat(token)}};return isomorphic_fetch__WEBPACK_IMPORTED_MODULE_1___default()(GITHUB_GRAPHQL_SERVER,fetchOptions).then(x=>x.json().then(x=>{if(x.errors){if(x.errors.length===1&&x.errors[0].message.includes(\"it could be a GitHub bug\")){return Promise.reject({type:\"GITHUB_INTERNAL_EXECUTION_ERROR\",error:x});}else if(x.errors.length===1&&x.errors[0].type===\"RATE_LIMITED\"){return Promise.reject({type:\"RATE_LIMIT_EXCEEDED\",error:x});}else{return Promise.reject({type:\"GRAPHQL_ERROR\",error:x});}}if(x.data===undefined){if(x.message&&x.message.includes(\"Bad credentials\")){return Promise.reject({type:\"BAD_CREDENTIALS\",error:x});}else{// See https://github.com/sourcecred/sourcecred/issues/350\nreturn Promise.reject({type:\"NO_DATA\",error:x});}}return Promise.resolve(x.data);}),e=>Promise.reject({type:\"FETCH_ERROR\",error:e}));}async function errorDisposition(e,token){if(e.type===\"FETCH_ERROR\"||e.type===\"GRAPHQL_ERROR\"||e.type===\"BAD_CREDENTIALS\"){return{type:\"FATAL\",err:e};}if(e.type===\"GITHUB_INTERNAL_EXECUTION_ERROR\"||e.type===\"NO_DATA\"){return{type:\"RETRY\",err:e};}if(e.type===\"RATE_LIMIT_EXCEEDED\"){try{const nominalRefreshTime=await quotaRefreshAt(token);const refreshTime=_resolveRefreshTime(new Date(),nominalRefreshTime);console.warn(\"GitHub rate limit exceeded; waiting for refresh at \"+refreshTime.toISOString());return{type:\"WAIT\",until:refreshTime,err:e};}catch(refreshError){// Fall back to waiting in 15-minute increments.\nconsole.warn(\"GitHub rate limit exceeded; waiting 15 minutes\");const delayMs=15*60*1000;return{type:\"WAIT\",until:new Date(Date.now()+delayMs),err:e};}}throw new Error(e.type);}/**\n * Determine the instant at which our GitHub quota will refresh.\n *\n * The returned promise may reject with a `GithubResponseError` or\n * string error message.\n */async function quotaRefreshAt(token){const b=_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"build\"];const query=b.query(\"RateLimitReset\",[],[b.field(\"rateLimit\",{},[b.field(\"resetAt\")])]);const postBody=JSON.stringify({query:_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"stringify\"].body([query],Object(_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"inlineLayout\"])()),variables:{}});const data=await tryGithubFetch(postBody,token);const dateString=data.rateLimit.resetAt;const result=new Date(dateString);if(isNaN(result)){throw\"got NaN quota reset time: \"+JSON.stringify(data);}return result;}/**\n * Given a `resetAt` date response from GitHub, determine the actual\n * date until which we want to wait. We clamp to a reasonable range and\n * apply some padding.\n */function _resolveRefreshTime(now,nominalRefreshTime){let delayMs=+nominalRefreshTime-+now;const[minDelayMs,maxDelayMs]=[0,60*60*1000];if(delayMs<minDelayMs||delayMs>maxDelayMs){const newDelayMs=Math.max(minDelayMs,Math.min(delayMs,maxDelayMs));console.warn(\"clamping refresh delay from \".concat(delayMs,\" ms to \").concat(newDelayMs,\" ms\"));delayMs=newDelayMs;}delayMs+=60*1000;// add 1 minute for padding around clock skew\nreturn new Date(+now+delayMs);}async function retryGithubFetch(postBody,token){const policy={maxRetries:5,jitterRatio:1.2,// We wait in 15-minute intervals, and quotas reset every hour, so\n// we shouldn't give up before waiting 4 times.\nmaxWaits:4};const retryResult=await Object(_util_retry__WEBPACK_IMPORTED_MODULE_8__[\"default\"])(async()=>{try{return{type:\"DONE\",value:await tryGithubFetch(postBody,token)};}catch(errAny){const err=errAny;return await errorDisposition(err,token);}},policy);switch(retryResult.type){case\"DONE\":return retryResult.value;case\"FAILED\":throw retryResult.err;default:throw new Error(retryResult.type);}}async function postQuery(_ref3,token){let{body,variables}=_ref3;const postBody=JSON.stringify({query:_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"stringify\"].body(body,Object(_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"inlineLayout\"])()),variables:variables});return retryGithubFetch(postBody,token).catch(error=>{switch(error.type){case\"GITHUB_INTERNAL_EXECUTION_ERROR\":case\"NO_DATA\":console.error(\"GitHub query failed! We're tracking these issues at \"+\"https://github.com/sourcecred/sourcecred/issues/350.\\n\"+\"If the error is a timeout or abuse rate limit, you can \"+\"try loading a smaller repo, or trying again in a few minutes.\\n\"+\"The actual failed response can be found below:\\n\"+\"=================================================\");console.error(error.error);break;case\"GRAPHQL_ERROR\":error.error.errors.forEach(error=>{if(error.type===\"NOT_FOUND\"){console.error(\"Unable to find the specified repository. Please check for typos \"+\"in the repository owner and name and confirm that you are using the correct token in \"+\"$SOURCECRED_GITHUB_TOKEN\");}else{console.error(\"Unexpected GraphQL error: \"+JSON.stringify({postBody:postBody,error:error}));}});break;case\"RATE_LIMIT_EXCEEDED\":console.error(\"You've exceeded your hourly GitHub rate limit.\\n\"+\"You'll need to wait until it resets.\");break;case\"FETCH_ERROR\":// Network error; no need for additional commentary.\nbreak;case\"BAD_CREDENTIALS\":console.error(\"An invalid token was supplied ($SOURCECRED_GITHUB_TOKEN). This is mostly likely caused by supplying a revoked token.\");break;default:console.error(\"Unexpected GitHub Error: \"+JSON.stringify({postBody:postBody,error:error}));}return Promise.reject(error);});}async function resolveRepositoryGraphqlId(postQuery,repoId){const b=_graphql_queries__WEBPACK_IMPORTED_MODULE_4__[\"build\"];const payload={body:[b.query(\"ResolveRepositoryId\",[b.param(\"owner\",\"String!\"),b.param(\"name\",\"String!\")],[b.field(\"repository\",{owner:b.variable(\"owner\"),name:b.variable(\"name\")},[b.field(\"id\")])])],variables:{owner:repoId.owner,name:repoId.name}};const data=await postQuery(payload);if(data.repository==null){throw new Error(\"No such repository: \".concat(Object(_repoId__WEBPACK_IMPORTED_MODULE_2__[\"repoIdToString\"])(repoId),\" \")+\"(response data: \".concat(JSON.stringify(data),\")\"));}return data.repository.id;}\n\n//# sourceURL=webpack:///./src/plugins/github/fetchGithubRepo.js?");

/***/ }),

/***/ "./src/plugins/github/repoId.js":
/*!**************************************!*\
  !*** ./src/plugins/github/repoId.js ***!
  \**************************************/
/*! exports provided: githubOwnerPattern, githubRepoPattern, makeRepoId, stringToRepoId, repoIdToString */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"githubOwnerPattern\", function() { return githubOwnerPattern; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"githubRepoPattern\", function() { return githubRepoPattern; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"makeRepoId\", function() { return makeRepoId; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stringToRepoId\", function() { return stringToRepoId; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"repoIdToString\", function() { return repoIdToString; });\n// Right now all RepoIds are assumed to refer to GitHub repos.\n// In the future, we may support other identifiers.\nconst githubOwnerPattern=\"[A-Za-z0-9-]+\";const githubRepoPattern=\"[A-Za-z0-9-._]+\";function makeRepoId(owner,name){const validOwner=new RegExp(\"^\".concat(githubOwnerPattern,\"$\"));const validRepo=new RegExp(\"^\".concat(githubRepoPattern,\"$\"));if(!owner.match(validOwner)){throw new Error(\"Invalid repository owner: \".concat(JSON.stringify(owner)));}if(!name.match(validRepo)){throw new Error(\"Invalid repository name: \".concat(JSON.stringify(name)));}return{owner,name};}function stringToRepoId(x){const pieces=x.split(\"/\");if(pieces.length!==2){throw new Error(\"Invalid repo string: \".concat(x));}return makeRepoId(pieces[0],pieces[1]);}function repoIdToString(x){return\"\".concat(x.owner,\"/\").concat(x.name);}\n\n//# sourceURL=webpack:///./src/plugins/github/repoId.js?");

/***/ }),

/***/ "./src/plugins/github/schema.js":
/*!**************************************!*\
  !*** ./src/plugins/github/schema.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return schema; });\n/* harmony import */ var _graphql_schema__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../graphql/schema */ \"./src/graphql/schema.js\");\nfunction schema(){const s=_graphql_schema__WEBPACK_IMPORTED_MODULE_0__;const types={DateTime:s.scalar(\"string\"),GitObjectID:s.scalar(\"string\"),GitTimestamp:s.scalar(\"string\"),Int:s.scalar(\"number\"),String:s.scalar(\"string\"),URI:s.scalar(\"string\"),PullRequestReviewState:s.enum([\"PENDING\",\"COMMENTED\",\"APPROVED\",\"CHANGES_REQUESTED\",\"DISMISSED\"]),ReactionContent:s.enum([\"THUMBS_UP\",\"THUMBS_DOWN\",\"LAUGH\",\"HOORAY\",\"CONFUSED\",\"HEART\",\"ROCKET\",\"EYES\"]),Repository:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),name:s.primitive(s.nonNull(\"String\")),owner:s.node(\"RepositoryOwner\"),issues:s.connection(\"Issue\"),pullRequests:s.connection(\"PullRequest\"),defaultBranchRef:s.node(\"Ref\"),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),Issue:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),title:s.primitive(s.nonNull(\"String\")),body:s.primitive(s.nonNull(\"String\")),number:s.primitive(s.nonNull(\"Int\")),author:s.node(\"Actor\"),comments:s.connection(\"IssueComment\"),reactions:s.connection(\"Reaction\"),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),PullRequest:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),title:s.primitive(s.nonNull(\"String\")),body:s.primitive(s.nonNull(\"String\")),number:s.primitive(s.nonNull(\"Int\")),mergeCommit:s.node(\"Commit\"),additions:s.primitive(s.nonNull(\"Int\")),deletions:s.primitive(s.nonNull(\"Int\")),author:s.node(\"Actor\"),comments:s.connection(\"IssueComment\"),// yes, PRs have IssueComments\nreviews:s.connection(\"PullRequestReview\"),reactions:s.connection(\"Reaction\"),createdAt:s.primitive(s.nonNull(\"DateTime\")),baseRefName:s.primitive(s.nonNull(\"String\"))}),IssueComment:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),body:s.primitive(s.nonNull(\"String\")),author:s.node(\"Actor\"),reactions:s.connection(\"Reaction\"),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),PullRequestReview:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),body:s.primitive(s.nonNull(\"String\")),author:s.node(\"Actor\"),state:s.primitive(s.nonNull(\"PullRequestReviewState\")),comments:s.connection(\"PullRequestReviewComment\"),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),PullRequestReviewComment:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),body:s.primitive(s.nonNull(\"String\")),author:s.node(\"Actor\"),reactions:s.connection(\"Reaction\"),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),Reaction:s.object({id:s.id(),content:s.primitive(s.nonNull(\"ReactionContent\")),user:s.node(\"User\",s.unfaithful([\"User\",\"Organization\"])),createdAt:s.primitive(s.nonNull(\"DateTime\"))}),Ref:s.object({id:s.id(),// Unlike most node references, this is guaranteed non-null (but\n// we have no way to express that).\ntarget:s.node(\"GitObject\")}),GitObject:s.union([\"Blob\",\"Commit\",\"Tag\",\"Tree\"]),Blob:s.object({id:s.id(),oid:s.primitive(s.nonNull(\"GitObjectID\"))}),Commit:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),oid:s.primitive(s.nonNull(\"GitObjectID\")),message:s.primitive(s.nonNull(\"String\")),author:/* GitActor */s.nested({// The GitHub schema indicates that `date` can be null, but does\n// not indicate when this might be the case.\ndate:s.primitive(s.nullable(\"GitTimestamp\")),user:s.node(\"User\",s.unfaithful([\"User\",\"Bot\"]))}),parents:s.connection(\"Commit\"),// In contrast to the author.date, this is both nonNull and is\n// specifically the authoredDate. Docs for author.date suggest that\n// field might be the commiter date instead.\nauthoredDate:s.primitive(s.nonNull(\"GitTimestamp\"))}),Tag:s.object({id:s.id(),oid:s.primitive(s.nonNull(\"GitObjectID\"))}),Tree:s.object({id:s.id(),oid:s.primitive(s.nonNull(\"GitObjectID\"))}),Actor:s.union([\"User\",\"Bot\",\"Organization\"]),// actually an interface\nRepositoryOwner:s.union([\"User\",\"Organization\"]),// actually an interface\nUser:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),login:s.primitive(s.nonNull(\"String\"))}),Bot:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),login:s.primitive(s.nonNull(\"String\"))}),Organization:s.object({id:s.id(),url:s.primitive(s.nonNull(\"URI\")),login:s.primitive(s.nonNull(\"String\"))})};return s.schema(types);}\n\n//# sourceURL=webpack:///./src/plugins/github/schema.js?");

/***/ }),

/***/ "./src/plugins/github/token.js":
/*!*************************************!*\
  !*** ./src/plugins/github/token.js ***!
  \*************************************/
/*! exports provided: validateToken */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateToken\", function() { return validateToken; });\n/**\n * Validates a token against know formatting.\n * Throws an error if it appears invalid.\n *\n * Personal access token\n * https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line\n *\n * Installation access token\n * https://developer.github.com/v3/apps/#create-a-new-installation-token\n */function validateToken(token){const accessTokenRE=/^gh[pousr]_[A-Za-z0-9_]*$/;const oldAccessTokenRE=/^[A-Fa-f0-9]{40}$/;if(accessTokenRE.test(token)||oldAccessTokenRE.test(token)){return token;}// We're currently being lenient with installation tokens, since we're not completely\n// sure on the exact format. We're only warning on unexpected values but leave it up\n// to the GitHub API to reject the token if it's actually invalid.\nconst installationAccessTokenRE=/^(v\\d+)\\.([A-Za-z0-9_]+)$/;const matches=installationAccessTokenRE.exec(token);if(matches!=null){const[_,version,hexCode]=matches;if(version!==\"v1\"){console.warn(\"Warning: GitHub installation access token has an unexpected version \\\"\".concat(version,\"\\\".\"));}if(hexCode.length!==40){console.warn(\"Warning: GitHub installation access token has an unexpected hexadecimal component \"+\"length of \".concat(hexCode.length,\".\"));}return token;}throw new Error(\"The token supplied to $SOURCECRED_GITHUB_TOKEN doesn't match any format known to work.\\n\"+\"Please verify the token \\\"\".concat(token,\"\\\" is correct, or report a bug if you think it should work.\"));}\n\n//# sourceURL=webpack:///./src/plugins/github/token.js?");

/***/ }),

/***/ "./src/util/dedent.js":
/*!****************************!*\
  !*** ./src/util/dedent.js ***!
  \****************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return dedent; });\n/*\n * A template tag function that performs dedenting on the template, but\n * not its arguments.\n *\n * For instance, given the template\n *\n *     |dedent`\\\n *     |    one ${one}\n *     |        two ${two}\n *     |    done`,\n *\n * where `one === \"1\"` and `two === \"\\n    2\"`, the template string\n * would expand to \"one 1\\n    two\\n    2\\ndone\". Note that four spaces\n * of indentation were stripped off of each of \"one\" and \"two\", but not\n * from \"2\".\n *\n * Lines that contain only whitespace are not used for measuring.\n */function dedent(strings){const lineLengths=strings.join(\"\").split(\"\\n\").filter(line=>line.trim().length!==0).map(line=>line.length-line.trimLeft().length);const trimAmount=Math.min.apply(null,lineLengths);const parts=[];for(let i=0;i<strings.length;i++){const trimmed=strings[i].split(\"\\n\").map((line,j)=>i===0||j>0?line.substr(trimAmount):line).join(\"\\n\");parts.push(trimmed);if(i<(arguments.length<=1?0:arguments.length-1)){parts.push(i+1<1||arguments.length<=i+1?undefined:arguments[i+1]);}}return parts.join(\"\");}\n\n//# sourceURL=webpack:///./src/util/dedent.js?");

/***/ }),

/***/ "./src/util/map.js":
/*!*************************!*\
  !*** ./src/util/map.js ***!
  \*************************/
/*! exports provided: toObject, fromObject, copy, mapKeys, mapValues, mapEntries, merge, pushValue, mapToArray */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"toObject\", function() { return toObject; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fromObject\", function() { return fromObject; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"copy\", function() { return copy; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapKeys\", function() { return mapKeys; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapValues\", function() { return mapValues; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapEntries\", function() { return mapEntries; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"merge\", function() { return merge; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pushValue\", function() { return pushValue; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mapToArray\", function() { return mapToArray; });\n/**\n * Convert a string-keyed map to an object. Useful for conversion to\n * JSON. If a map's keys are not strings, consider invoking `mapKeys`\n * first.\n */function toObject(map){const result={};for(const[k,v]of map.entries()){result[k]=v;}return result;}/**\n * Convert an object to a map. The resulting map will have key-value\n * pairs corresponding to the enumerable own properties of the object in\n * iteration order, as returned by `Object.keys`.\n */function fromObject(object){const result=new Map();const keys=Object.keys(object);for(const key of keys){result.set(key,object[key]);}return result;}/**\n * Shallow-copy a map, allowing upcasting its type parameters.\n *\n * The `Map` type constructor is not covariant in its type parameters,\n * which means that (e.g.) `Map<string, Dog>` is not a subtype of\n * `Map<string, Animal>` even if `Dog` is a subtype of `Animal`. This is\n * because, given a `Map<string, Animal>`, one can insert a `Cat`, which\n * would break invariants of existing references to the variable as a\n * map containing only `Dog`s.\n *\n *     declare class Animal {};\n *     declare class Dog extends Animal {};\n *     declare class Cat extends Animal {};\n *     declare var dogMap: Map<string, Dog>;\n *     const animalMap: Map<string, Animal> = dogMap;  // must fail\n *     animalMap.set(\"tabby\", new Cat());  // or we could do this...\n *     (dogMap.values(): Iterator<Dog>);  // ...now contains a `Cat`!\n *\n * This problem only exists when a map with existing references is\n * mutated. Therefore, when we shallow-copy a map, we have the\n * opportunity to upcast its type parameters: `copy(dogMap)` _can_ be a\n * `Map<string, Animal>`.\n */function copy(map){const entries=map.entries();return new Map(entries);}/**\n * Map across the keys of a map. Note that the key-mapping function is\n * provided both the key and the value for each entry.\n *\n * The key-mapping function must be injective on the map's key set. If\n * it maps two distinct input keys to the same output key, an error may\n * be thrown.\n */function mapKeys(map,f){const result=new Map();for(const[k,v]of map.entries()){const outK=f(k,v);if(result.has(outK)){throw new Error(\"duplicate key: \"+String(outK));}result.set(outK,v);}return result;}/**\n * Map across the values of a map. Note that the value-mapping function\n * is provided both the key and the value for each entry.\n *\n * There are no restrictions on the value-mapping function (in\n * particular, it need not be injective).\n */function mapValues(map,g){const result=new Map();for(const[k,v]of map.entries()){result.set(k,g(k,v));}return result;}/**\n * Map simultaneously across the keys and values of a map.\n *\n * The key-mapping function must be injective on the map's key set. If\n * it maps two distinct input keys to the same output key, an error may\n * be thrown. There are no such restrictions on the value-mapping\n * function.\n */function mapEntries(map,h){const result=new Map();for(const[k,v]of map.entries()){const[outK,outV]=h(k,v);if(result.has(outK)){throw new Error(\"duplicate key: \"+String(outK));}result.set(outK,outV);}return result;}/**\n * Merge maps without mutating the arguments.\n *\n * Merges multiple maps, returning a new map which has every key from\n * the source maps, with their corresponding values. None of the inputs\n * are mutated. In the event that multiple maps have the same key, an\n * error will be thrown.\n */function merge(maps){const result=new Map();let updates=0;for(const map of maps){for(const[key,value]of map.entries()){result.set(key,value);if(result.size!==++updates){throw new Error(\"Maps have duplicate key: \".concat(String(key)));}}}return result;}/**\n * Given a map whose values are arrays, push an element onto the array\n * corresponding to the given key. If the key is not in the map, first\n * insert it with value a new empty array.\n *\n * If the key is already in the map, its value will be mutated, not\n * replaced.\n */function pushValue(map,key,value){let arr=map.get(key);if(arr==null){map.set(key,arr=[]);}arr.push(value);return arr;}/**\n * Given a Map, transform its entries into an Array using a\n * provided transformer function.\n */function mapToArray(map,fn){return Array.from(map.entries()).map(fn);}\n\n//# sourceURL=webpack:///./src/util/map.js?");

/***/ }),

/***/ "./src/util/null.js":
/*!**************************!*\
  !*** ./src/util/null.js ***!
  \**************************/
/*! exports provided: map, get, orThrow, orElse, filterList */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"map\", function() { return map; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"get\", function() { return get; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"orThrow\", function() { return orThrow; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"orElse\", function() { return orElse; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"filterList\", function() { return filterList; });\n/**\n * Utilities for working with nullable types: `?T = T | null | void`.\n *\n * These functions use the native runtime representation, as opposed to\n * creating an `Optional<T>` wrapper class. This ensures that they have\n * minimal runtime cost (just a function call), and that they are\n * trivially interoperable with other code.\n *\n * When a value of type `?T` is `null` or `undefined`, we say that it is\n * _absent_. Otherwise, it is _present_.\n *\n * Some functions that typically appear in such libraries are not\n * needed:\n *\n *   - `join` (`??T => ?T`) can be implemented as the identity function,\n *     because the Flow types `??T` and `?T` are equivalent;\n *   - `flatMap` (`?T => (T => ?U) => ?U`) can be implemented simply as\n *     `map`, again because `??T` and `?T` are equivalent;\n *   - `first` (`?T => ?T => ?T`) can be implemented simply as `orElse`,\n *     again because `??T` and `?T` are equivalent;\n *   - `isPresent` (`?T => boolean`) doesn't provide much value over the\n *     equivalent abstract disequality check;\n *   - constructors like `empty` (`() => ?T`) and `of` (`T => ?T`) are\n *     entirely spurious.\n *\n * Other functions could reasonably be implemented, but have been left\n * out because they have rarely been needed:\n *\n *   - `filter` (`?T => (T => boolean) => ?T`);\n *   - `forEach` (`?T => (T => void) => void`);\n *   - `orElseGet` (`?T => (() => T) => T`), which is useful in the case\n *      where constructing the default value is expensive.\n *\n * (Of these three, `orElseGet` would probably be the most useful for\n * our existing codebase.)\n */ /**\n * Apply the given function inside the nullable. If the input is absent,\n * then it will be returned unchanged. Otherwise, the given function\n * will be applied.\n */function map(x,f){return x!=null?f(x):x;}/**\n * Extract the value from a nullable. If the input is present, it will\n * be returned. Otherwise, an error will be thrown with the provided\n * message (defaulting to the string representation of the absent input).\n */function get(x,errorMessage){if(x==null){throw new Error(errorMessage!=null?errorMessage:String(x));}else{return x;}}/**\n * Extract the value from a nullable. If the input is present, it will\n * be returned. Otherwise, an error will be thrown, with message given\n * by the provided function.\n */function orThrow(x,getErrorMessage){if(x==null){throw new Error(getErrorMessage());}else{return x;}}/**\n * Extract the value from a nullable, using the provided default value\n * in case the input is absent.\n */function orElse(x,defaultValue){return x!=null?x:defaultValue;}/**\n * Filter nulls and undefined out of an array, returning a new array.\n *\n * The functionality is easy to implement without a util method (just call\n * `filter`); however Flow doesn't infer the type of the output array based on\n * the callback that was passed to filter. This method basically wraps filter\n * in a type-aware way.\n */function filterList(xs){// A type-safe way to implement this would be:\n/*:: (xs.flatMap((x) => x == null ? [] : [x]): T[]); */ // For performance, we instead take an unsafe route.\nreturn xs.filter(x=>x!=null);}\n\n//# sourceURL=webpack:///./src/util/null.js?");

/***/ }),

/***/ "./src/util/retry.js":
/*!***************************!*\
  !*** ./src/util/retry.js ***!
  \***************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return retry; });\nfunction ownKeys(object,enumerableOnly){var keys=Object.keys(object);if(Object.getOwnPropertySymbols){var symbols=Object.getOwnPropertySymbols(object);if(enumerableOnly){symbols=symbols.filter(function(sym){return Object.getOwnPropertyDescriptor(object,sym).enumerable;});}keys.push.apply(keys,symbols);}return keys;}function _objectSpread(target){for(var i=1;i<arguments.length;i++){var source=arguments[i]!=null?arguments[i]:{};if(i%2){ownKeys(Object(source),true).forEach(function(key){_defineProperty(target,key,source[key]);});}else if(Object.getOwnPropertyDescriptors){Object.defineProperties(target,Object.getOwnPropertyDescriptors(source));}else{ownKeys(Object(source)).forEach(function(key){Object.defineProperty(target,key,Object.getOwnPropertyDescriptor(source,key));});}}return target;}function _defineProperty(obj,key,value){if(key in obj){Object.defineProperty(obj,key,{value:value,enumerable:true,configurable:true,writable:true});}else{obj[key]=value;}return obj;}// The outcome of a single attempt of a retryable operation.\n// The final result of executing an operation after retrying zero or more\n// times.\nfunction defaultPolicy(){return{initialDelayMs:1000,backoffRatio:2.0,jitterRatio:1.2,maxRetries:3,maxWaits:1};}/**\n * Run a retryable operation until it terminates or exhausts its retry\n * policy. If `attempt` ever rejects, this function also immediately\n * rejects with the same value.\n */async function retry(attempt,policy){let io=arguments.length>2&&arguments[2]!==undefined?arguments[2]:realIo;const fullPolicy=_objectSpread(_objectSpread({},defaultPolicy()),policy);let nextRetryDelayMs=fullPolicy.initialDelayMs;let retries=0;let waits=0;while(true){const outcome=await attempt();switch(outcome.type){case\"DONE\":return{type:\"DONE\",value:outcome.value};case\"FATAL\":return{type:\"FAILED\",err:outcome.err};case\"RETRY\":{if(retries>=fullPolicy.maxRetries){return{type:\"FAILED\",err:outcome.err};}retries++;const delayMs=nextRetryDelayMs*io.rollJitter(fullPolicy.jitterRatio);await io.sleepMs(delayMs);nextRetryDelayMs*=fullPolicy.backoffRatio;break;}case\"WAIT\":{if(waits>=fullPolicy.maxWaits){return{type:\"FAILED\",err:outcome.err};}waits++;const now=io.now();const delayMs=outcome.until-now;if(delayMs<0){const fmt=d=>\"@\".concat((+d/1000).toFixed(3));throw new Error(\"wait-until time in the past: \".concat(fmt(outcome.until),\" < \").concat(fmt(now)));}await io.sleepMs(delayMs);break;}// istanbul ignore next: unreachable per flow\ndefault:throw new Error(outcome.type);}}// istanbul ignore next: unreachable\n// ESLint knows that this next line is unreachable, but Flow doesn't. :-)\n// eslint-disable-next-line no-unreachable\nthrow new Error(\"unreachable\");}const realIo={// istanbul ignore next: impure non-test implementation\nnow(){return new Date();},// istanbul ignore next: impure non-test implementation\nsleepMs(ms){return new Promise(resolve=>{setTimeout(resolve,ms);});},// istanbul ignore next: impure non-test implementation\nrollJitter(r){return 1+Math.random()*(r-1);}};\n\n//# sourceURL=webpack:///./src/util/retry.js?");

/***/ }),

/***/ "better-sqlite3":
/*!*********************************!*\
  !*** external "better-sqlite3" ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"better-sqlite3\");\n\n//# sourceURL=webpack:///external_%22better-sqlite3%22?");

/***/ }),

/***/ "deep-freeze":
/*!******************************!*\
  !*** external "deep-freeze" ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"deep-freeze\");\n\n//# sourceURL=webpack:///external_%22deep-freeze%22?");

/***/ }),

/***/ "isomorphic-fetch":
/*!***********************************!*\
  !*** external "isomorphic-fetch" ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"isomorphic-fetch\");\n\n//# sourceURL=webpack:///external_%22isomorphic-fetch%22?");

/***/ }),

/***/ "json-stable-stringify":
/*!****************************************!*\
  !*** external "json-stable-stringify" ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = require(\"json-stable-stringify\");\n\n//# sourceURL=webpack:///external_%22json-stable-stringify%22?");

/***/ })

/******/ });
});